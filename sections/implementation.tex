\section{Prototype Implementation and Evaluation} \label{sec:impl}

% TODO: Intro for the section

\subsection{Architecture of the Coq Kernel}

The core type checking algorithm is found in Coq's \emph{kernel}.
Before reaching the kernel, terms go through a round of \emph{pretyping}
where existential metavariables (essentially typed holes) are solved for
and the recursive indices of fixpoints are determined.
Size inference is implemented as an augmentation of the existing type inference algorithm.
\autoref{fig:kernel} summarizes the relevant file/module structure.
Most of the added code specifically for size inference is in the \texttt{Sized} and \texttt{Subsizing} modules.
(\texttt{Subsizing} is only separate from \texttt{Sized} to break circular dependencies: it relies on the global environment, while the environment depends on \texttt{Sized}.)

\begin{figure}
\dirtree{%
.1 coq.
.2 lib.
.3 WeightedDigraph\DTcomment{graph data structure and algorithms for constraints}.
.2 pretyping.
.2 kernel.
.3 Constr\DTcomment{core AST and traversals}.
.3 Environ\DTcomment{environments and lookups}.
.3 Reduction\DTcomment{reduction and convertibility}.
.3 Inductive\DTcomment{functions on (co)fixpoints (guard checking)}.
.3 Typeops\DTcomment{entrypoint to type checker for terms}.
.3 Term\_typing\DTcomment{entrypoint to type checker for declarations}.
.3 Sized\DTcomment{constructs and functions for sized types}.
.3 Subsizing\DTcomment{producing subsizing constraints}.
}
\caption{Selected excerpts of the Coq codebase structure}
\label{fig:kernel}
\end{figure}

The \texttt{Sized} module contains several submodules, four of which are relevant to our performance discussion:
\begin{itemize}
  \item \texttt{State} keeps track of the (position) size variables that have been used;
  \item \texttt{Constraints} defines the data structure for and operations on constraint sets;
  \item \texttt{SMap} defines the data structure for and operations on size substitutions; and
  \item \texttt{RecCheck} implements the \RecCheck and \solve algorithms.
\end{itemize}

Sized typing is implemented as a vernacular flag that can be set and unset, just like guard checking.
By default, the flag is off; the commands
$$\coqinline{Set Sized Typing. Unset Guard Checking.}$$
will enable sized typing only.
If both are set, then guard checking will only occur if sized typing fails.
When sized typing is not set, size annotations are still added, but constraints are not collected,
meaning that things like type aliases that are checked with sized typing off will still behave as expected in code checked with sized typing on,
but global definitions checked with sized typing off will never be size-preserving.

\subsection{Analysis of Performance Degradation}

When compiling parts of the Coq standard library with sized typing on, we noticed a severe performance degradation.
This is bad news if we hope to replace guard checking with sized typing,
or even if we simply wish to use sized typing as the primary method of termination or productivity checking throughout.
In particular, we examine compilation of the \texttt{Coq.setoid\_ring.Field\_theory} library%
\footnote{This file can be found in the artifact at \texttt{coq/theories/setoid\_ring/Field\_theory.v}.}
up to and excluding the \fnormeval theorem.
(We henceforth refer to this part of the library simply as \fieldtheory.)
In this part of the file alone, we find a $14\times$ increase in compilation time with \texttt{coqc}.
We investigate possible causes of this performance degredation and discuss possible solutions.

\subsubsection{Profiling \texttt{Sized} Functions}

To measure the performance degredation, we compare compiling \fieldtheory against itself with sized typing on and guard checking off, which we refer to as \fieldtheorysized.
Both compilations are run five times each.
The compilation times are significantly different ($t = 1096.30$, $p \ll 0.01$),
with \fieldtheory's compilation time at $19.582 \pm 0.950$ seconds and \fieldtheorysized's at $281.664 \pm 0.469$ seconds.

To identify the source of the slowdown and test our hypothesis that it is due to sized typing,
we profile the performance of functions relevant to the \texttt{Sized} module during the compilation.
We divide these functions into four groups: the \solve and \RecCheck functions, the \texttt{foldmap}%
\footnote{This is the \texttt{foldmap\_annots} function in \texttt{coq/kernel/Constr.ml}.}
function common to all operations manipulating size annotations on the AST (such as applying size substitutions),
the functions in \texttt{State}, and the functions in \texttt{Constraints}.
\autoref{table:timing} summarizes the results, as well as the relative time spent in the functions in \fieldtheorysized.
All of the $t$-statistics yield $p \ll 0.01$.
% meaning that the differences between the sized and unsized times are statistically significant.

\begin{table}
\centering
\begin{tabular}{| l | r | r | r | r |}
\hline
\textbf{Function(s)} & \textbf{Unsized time (s)} & \textbf{Sized time (s)} & \textbf{$t$} & \textbf{Sized time \%} \\
\hline
\textbf{\solve, \RecCheck}    & $0.620 \pm 0.002$ & $183.506 \pm 0.474$ &  865 & 65.2  \\
\textbf{\texttt{foldmap}}     & $0.348 \pm 0.003$ & $ 40.774 \pm 0.084$ & 1078 & 14.4  \\
\textbf{\texttt{State}}       & $0.183 \pm 0.002$ & $ 27.807 \pm 0.146$ &  422 &  9.87 \\
\textbf{\texttt{Constraints}} & $0.313 \pm 0.002$ & $  7.920 \pm 0.037$ &  455 &  2.81 \\
\hline
\textbf{Total}                & $1.464 \pm 0.009$ & $260.007 \pm 0.741$ &      & 92.3  \\
\hline
\end{tabular}
\caption{Compilation times of \fieldtheory vs. \fieldtheorysized}
\label{table:timing}
\end{table}

Nearly two thirds of the compilation time in \fieldtheorysized is taken up by \solve and \RecCheck,
while less than one third is taken up by other \texttt{Sized}-related overhead.
We conjecture that some of this overhead can be reduced with more clever implementations.
For instance, instead of explicitly performing size substitutions, the sizes can be looked up as needed,
or instead of explicitly passing around a size state, we could use a state monad or a mutable global state.
We therefore focus our attention on \solve and \RecCheck, where performance degradation may not be limited to mere implementational details.

\subsubsection{Confirming Time Complexity of \solve and \RecCheck}

As shown in \autoref{sec:algorithm}, given a constraint graph from constraint graph $C$ with size variables $V$,
the time complexities of \solve and \RecCheck are $O(\norm{V}\norm{C})$.
Indeed, in \autoref{fig:linregress}, plotting the mean execution times of each of the 301 calls to \solve and 9 calls to \RecCheck
against the number of variables multiplied by the number constraints involved in each call,
we see a strong positive correlation ($r = 0.995$).

To verify that the execution time is dominated by a linear relationship to $\norm{V}\norm{C}$ at large values, we fit the data to a linear model and quantify the goodness of fit.
Using a na\"ive ordinary least-squares regression, the residual plot reveals a fair amount of increase in variability of the residuals roughly proportional to $\norm{V}\norm{C}$ (i.e. the data is heteroskedastic).
This could be explained by the fact that with more variables and constants, the shape of the constraint graph varies more as well.
To take this into account, we instead use a least-squares \emph{percentage} regression~\citep{lspr},
which minimizes the sum of \emph{relative} squared residuals.
The model is overlaid on \autoref{fig:linregress} ($R^2 = 0.999$), with the the resulting relative residuals plot in \autoref{fig:residuals}
(note the logarithmic scale of the independent variable used for clarity).

For large values of $\norm{V}\norm{C}$, the residuals are scattered uniformly about zero, indicating that the linear model is suitable.
For smaller values, the residuals appear to follow some unexplained pattern,
possibly due to dominance of other factors proportional to, say, $\norm{V}$ or $\norm{C}$, due to traversal of the size variable set or constaint set.
\autoref{fig:residuals-zoom} show the absolute residuals at these smaller values;
since they are smaller than half a millesecond, these effects may be due to other irrelevant noise.

\subsubsection{An Explosion of Size Variables}

Now that we have verified the time complexities of \solve and \RecCheck,
we can conclude that the performance degredation is likely due to a large number of variables and constraints involved in these calls.
% TODO: Show the distribution of Vs and Cs as well as the concrete data for the worst calls.
