\section{Metatheoretical Results}
\label{sec:metatheory}

In this section, we describe the metatheory of \lang.
Some of the metatheory is inherited or essentially similar to past work~\citep{cic-hat-minus,cc-hat-omega,cic-hat},
although we must adapt key proofs to account for differences in subtyping and definitions.
Complete proofs for a language like \lang are too involved to present in full,
so we provide only key lemmas and proof sketches.

In short, \lang satisfies confluence and subject reduction, with the same caveats as in CIC for cofixpoints.
While strong normalization and logical consistency have been proven for a variant of \lang
with features that violate backward compatibility,
proofs for \lang itself remain future work.

\subsection{Confluence}

Recall that we define $\rhd$ as the congruent closure of \reduction and $\rhd^*$ as the reflexive--transitive closure of $\rhd$.

\begin{theorem}[Confluence]
\label{thm:metatheory:confluence}
  If $\gg \vdash e \rhd^* e_1$ and $\gg \vdash e \rhd^* e_2$,
  then there is some term $e'$ such that $\gg \vdash e_1 \rhd^* e'$ and $\gg \vdash e_2 \rhd^* e'$.
\end{theorem}

\begin{proof}[{[sketch]}]
  We use the Takahashi translation technique due to \citet{takahashitrans},
  which is a simplification of the standard parallel reduction technique.
  It uses the Takahashi translation $e^\dagger$ of terms $e$,
  defined as the simultaneous single-step reduction of all
  $\beta\zeta\delta\Delta\iota\mu\nu$-redexes of $e$ in left-most inner-most order.
  The proof is relatively standard thanks to reduction being purely syntactic and untyped.
  % Is it though?
\end{proof}

\subsection{Subject Reduction}
\label{sec:metatheory:sub-red}

Subject reduction does not hold in \lang or in Coq due to the way coinductives are presented.
This is a well-known problem, discussed previously in a sized-types setting by \citet{cc-hat-omega},
on which our presentation of coinductives is based,
as well as by the Coq developers%
\footnote{The discussion of the problem and suggested solutions can be found here: \url{https://github.com/coq/coq/issues/5288/}.}.

In brief, the current presentation of coinductives requires that cofixpoint reduction be \textit{restricted},
\ie occurring only when it is the target of a case expression.
This allows for strong normalization of cofixpoints in much the same way restricting fixpoint reduction to when the recursive argument is syntactically a fully-applied constructor does.
One way this can break subject reduction is by making the type of a case expression not be convertible before and after the cofixpoint reduction.
As a concrete example, consider the following coinductive definition for conaturals.
\begin{displaymath}
  \seq{\assm{\Conat}{\Type{}}} \coloneqq {\seq{\assm{\Zero}{\Conat}, \assm{\Succ}{\Conat \to \Conat}}}
\end{displaymath}
For some motive $P$ and branch $e$, we have the following $\nu$-reduction.
\begin{align*}
  &\caseof*{\erase{P}}{\cofix*{1}{\defn{\omega}{\Conat}{\app{\Succ}{\omega}}}}{\seq{\Succ \Rightarrow e}} \rhd_\nu \\
  &\caseof*{\erase{P}}{\app{\Succ}{(\cofix*{1}{\defn{\omega}{\Conat}{\app{\Succ}{\omega}}})}}{\seq{\Succ \Rightarrow e}}
\end{align*}
Assuming both terms are well typed, the former has type $\app{P}{(\cofix*{1}{\defn{\omega}{\Conat}{\app{\Succ}{\omega}}})}$ while the latter has type $\app{P}{(\app{\Succ}{(\cofix*{1}{\defn{\omega}{\Conat}{\app{\Succ}{\omega}})}})}$, but for an arbitrary $P$ these aren't convertible without allowing cofixpoints to reduce arbitrarily.

\begin{figure}
  \fbox{$\gg \vdash e \reduce_{\beta\zeta\delta\Delta\iota\mu\nu'} e$} \hfill
  \vspace{-3ex}
  \begin{align*}
    \dots & \\
    \gg \vdash q_m & \reduce_{\nu'} \substvec{e_m}{f_k}{q_k} \\
    \textit{where} ~ & \forall i \in \vec{k}, q_i \equiv \cofix{i}{f_k}{t_k}{e_k}
  \end{align*}
  \caption{Reduction rules with unrestricted cofixpoint reduction}
  \label{fig:reduction-alt}
\end{figure}

On the other hand, if we do allow unrestricted $\nu'$-reduction as in \autoref{fig:reduction-alt}, subject reduction does hold,
at the expense of normalization,
as a cofixpoint on its own could reduce indefinitely.

\begin{theorem}[Subject Reduction]
  \label{thm:metatheory:sr}
  Let $\Sigma$ be a well-formed signature.
  Suppose $\rhd$ includes unrestricted $\nu'$-reduction of cofixpoints.
  Then $\gg \vdash e : t$ and $e \rhd e'$ implies $\gg \vdash e' : t$.
\end{theorem}

\begin{proof}[{[sketch]}]
  By induction on $\gg \vdash e : t$.  Most cases are straightforward,
  making use of confluence when necessary, such as for a lemma of
  $\Pi$-injectivity to handle $\beta$-reduction in \refrule{app}.
  %
  The case for \refrule{case} where $e \rhd e'$ by $\iota$-reduction relies on the fact that
  if $x$ is the name of a \coinductive type and appears strictly positively in $t$,
  then $x$ appears covariantly in $t$.
  (This is only true without nested \coinductive types, which \lang disallows in well-formed signatures.)

  The case for \refrule{case} and $e$ (guarded) $\nu$-reduces to $e'$ requires an unrestricted $\nu$-reduction.
  After guarded $\nu$-reduction, the target (a cofixpoint) appears in the motive unguarded by a case expression, but must be unfolded to re-establish typing the type $t$.
\end{proof}

\subsubsection{The Problem with Nested Inductives}

\newcommand{\nat}{\const{N}}

Recall from \autoref{sec:typing} that we disallow nested \coinductive types.
This means that when defining a \coinductive type, it cannot recursively appear as the parameter of another type.
For instance, the following definition $\nat$, while equivalent to $\Nat$,
is disallowed due to the appearance of $\nat$ as a parameter of $\Box$.
\begin{align*}
  \seq{\assm{\app{\Box}{(\assm{A}{\Type{}})}}{\Type{}}} &\coloneqq \seq{\assm{\MkBox}{A \rightarrow \app{\Box}{A}}} \\
  \seq{\assm{\nat}{\Type{}}} &\coloneqq \seq{\assm{\Zero}{\nat}, \assm{\Succ}{\app{\Box}{\nat} \to \nat}}
\end{align*}
Notice that we have the subtyping relation $\nat^\upsilon \leq \nat^{\hat{\upsilon}}$,
but as all parameters are invariant for backward compatibility and need to be convertible,
we do \emph{not} have $\app{\Box^\infty}{\nat^\upsilon} \leq \app{\Box^\infty}{\nat^{\hat{\upsilon}}}$.
But because case expressions on some target $\nat^{\hat{s}}$ force recursive arguments to have size $s$ exactly,
and the target also has type $\nat^{\hat{\hat{s}}}$ by cumulativity,
the argument of $\Succ$ could have both type $\app{\Box^\infty}{\nat^s}$ and $\app{\Box^\infty}{\nat^{\hat{s}}}$, violating convertibility.
We exploit this fact and break subject reduction explicitly with the following counterexample term.
\begin{displaymath}
\begin{array}{l}
  \caseof*{\erase{\abs{\any}{\nat}{\nat^\infty}}}{\app{\Succ}{(\app{\MkBox}{\nat^{\hat{\upsilon}}}{\Zero})}}{\\
  \seq{\Zero \Rightarrow \Zero,\\
  \phantom{\langle} \Succ \Rightarrow \app{(\abs{A}{\Type{}}{\abs{x}{A}{\Zero}})}{(\app{\Box^\infty}{\nat^{\hat{\hat{\upsilon}}}})}}}
\end{array}
\end{displaymath}
By cumulativity, the target can be typed as $\nat^{\hat{\upsilon}^{3}}$ (that is, with size $\hat{\hat{\hat{\upsilon}}}$).
By \refrule{case}, the second branch must then have type $\prod{x}{\app{\Box}{\nat^{\hat{\hat{\upsilon}}}}}{\nat^\infty}$ (and so it does).
Then the case expression is well typed with type $\nat^\infty$.
However, once we reduce the the case expression, we end up with a term that is no longer well typed.
\begin{displaymath}
  \app{(\abs{A}{\Type{}}{\abs{x}{A}{\Zero}})}
    {(\app{\Box^\infty}{\nat^{\hat{\hat{\upsilon}}}})}
    {(\app{\MkBox}{\nat^{\hat{\upsilon}}}{\Zero})}
\end{displaymath}
By \refrule{app}, the second argument should have type $\app{\Box^\infty}{\nat^{\hat{\hat{\upsilon}}}}$ (or a subtype thereof), but it cannot:
the only type the second argument can have is $\app{\Box^\infty}{\nat^{\hat{\upsilon}}}$.

There are several possible solutions, all threats to backward compatibility.
\CIChat's solution is to require that constructors be fully-applied and that their parameters be bare terms,
so that we are forced to write $\app{\MkBox}{\nat}{\Zero}$.
The problem with this is that Coq treats constructors essentially like functions,
and ensuring that they are fully applied with bare parameters would require either reworking how they are represented internally
or adding an intermediate step to elaborate partially-applied constructors into functions whose bodies are fully-applied constructors.
The other solution, as mentioned, is to add polarities back in, so that $\Box$ with positive polarity in its parameter yields the subtyping relation $\app{\Box^\infty}{\nat^{\hat{\upsilon}}} \leq \app{\Box^\infty}{\nat^{\hat{\hat{\upsilon}}}}$.

Interestingly, because the implementation infers all size annotations from a completely bare program,
our counterexample and similar ones exploiting explicit size annotations aren't directly expressible,
and don't appear to be generated by the algorithm, which would solve for the smallest size annotations.
For the counterexample, in the second branch, the size annotation would be (a size constrained to be equal to) $\hat{\upsilon}$.
We conjecture that the terms synthesized by the inference algorithm do indeed satisfy subject reduction even in the presence of nested \coinductives
by being a strict subset of all well-typed terms that excludes counterexamples like the above.

\subsubsection{Bareness of Type Annotations}\label{sec:metatheory:sr:bare}

As mentioned in \autoref{sec:typing:syntax}, type annotations on functions and let expressions
as well as case expression motives and \cofixpoint types
need to be bare terms (or position terms, for the latter) to maintain subject reduction.
To see why, suppose they were not bare, and consider the term
$\app{(\fix*{1}{\defn{f^1}{\Nat^\tau \rightarrow \Nat^\tau}{\abs{n}{\Nat^{\hat{\tau}}}{n}}})}{(\app{\Succ}{\Zero})}$.
Under empty environments, the fixpoint argument is well typed with type $\Nat^{\hat{\hat{s}}}$ for any size expression $s$,
while the fixpoint itself is well typed with type $\Nat^{r} \rightarrow \Nat^{r}$ for any size expression $r$.
For the application to be well typed, it must be that $r$ is $\hat{\hat{s}}$,
and the entire term has type $\Nat^{\hat{\hat{s}}}$.

By the $\mu$-reduction rule, this steps to the term $\app{(\abs{n}{\Nat^{\hat{\tau}}}{n})}{(\app{\Succ}{\Zero})}$.
Unfortunately, the term is no longer well typed, as $\app{\Succ}{\Zero}$ cannot be typed with type $\Nat^{\hat{\tau}}$ as is required.
By erasing the type annotation of the function,
there is no longer a restriction on what size the function argument must have,
and subject reduction is no longer broken.
An alternate solution is to substitute $\tau$ for $\hat{s}$ during $\mu$-reduction,
but this requires typed reduction to know what the correct size to substitute is,
violating backward compatibility with Coq,
whose reduction and convertibility rules are untyped.

\subsection{Strong Normalization and Logical Consistency}\label{sec:metatheory:sn}

Following strong normalization and logical consistency for \CIChatminus and \CChatomega,
we conjecture that they hold for \lang as well.
We present some details of a model constructed in our a proof attempt;
unfortunately, the model requires changes to \lang that are backward
incompatible with Coq, so we don't pursue it further.
We discuss from where these backward-incompatible changes arise for posterity.

\begin{conjecture}[Strong Normalization]\label{thm:metatheory:sn}
  %
  If $\gg \vdash e : t$ then there are no infinite reduction sequences starting from $e$.
  %
\end{conjecture}

\begin{conjecture}[Logical Consistency]\label{thm:metatheory:lc}
  %
  There is no $e$ such that $\mt, \mt \vdash e : \prod{p}{\Prop}{p}$.
  %
\end{conjecture}

\iffalse
Note that strong normalization is a stricter requirement than Coq, which is only \emph{weakly} normalizing:
every well-typed term has \emph{some} finite reduction sequence.
This relaxation enables more programs to pass the guard predicates while still being consistent.
For instance, the first fixpoint definition is accepted, as \texttt{x} is never used,
but the second is not.

\begin{minted}{coq}
Fixpoint f (u: unit): unit := let x := f u in tt.
Fail Fixpoint f (u: unit): False := let x := f u in x.
\end{minted}
\fi

\subsubsection{Proof Attempt and Apparent Requirements for Set-Theoretic Model}

In attempting to prove normalization and consistency, we developed a variant of
\lang called \langAnother which made a series of simplifying assumptions
suggested by the proof attempt:

\begin{itemize}
  \item Reduction, subtyping, and convertibility are typed, as is the case for
    most set-theoretic models.
    That is, each judgement requires the type of the terms,
    and the derivation rules may have typing judgements as premises.
  \item A new size irrelevant typing judgement is needed, similar to that
    introduced by \citet{barras-thesis}. While \lang is probably size
    irrelevant, this is not clear in the model without an explicit judgment.
  \item Fixpoint type annotations require explicit size annotations
    (\ie are no longer merely position terms) and explicitly abstract over a size
    variable, and fixpoints are explicitly applied to a size expression.
    The typing rule no longer erases the type, and the size in the fixpoint type
    is fixed.
    \begin{mathparpagebreakable}
      \inferrule*[right=\defrule{fix-explicit}]
      { \Gamma (f : t) \vdash e : \subst{t}{\upsilon}{\hat{\upsilon}} }
      { \Gamma \vdash \fixE{\upsilon}{f}{t}{e}{s} : \subst{t}{\upsilon}{s}}
    \end{mathparpagebreakable}
    The fixpoint above binds the size variable $\upsilon$ in $t$ and in $e$.
    The reduction rule adds an additional substitution of the predecessor of the size expression,
    in line with how $f$ may only be called in $e$ with a smaller size.
    \begin{mathparpagebreakable}
      \Gamma \vdash \app{\fixE{\upsilon}{f}{t}{e}{\hat{s}}\,}{\vec{b}}{(\app{c_\ell}{\vec{p}}{\vec{a}})}
      \rhd_\mu \app{\subst{\subst{e}{\upsilon}{s}}{f}{\fixE{\upsilon}{f}{t}{e}{s}}}{\vec{b}}{(\app{c_\ell}{\vec{p}}{\vec{a}})}
    \end{mathparpagebreakable}
  \item Rather than inductive definitions in general, only predicative W types are considered.
    W types can be defined as an inductive type:
    \begin{mathparpagebreakable}
      \seq{\app{\W}{(\assm{A}{U})}{(\assm{B}{A \rightarrow U})}} \coloneqq
      \seq{\assm{\Sup}{(\assm{a}{A}) \rightarrow (\assm{b}{\app{B}{a} \rightarrow \app{\W}{A}{B}}) \rightarrow \app{\W}{A}{B}}}
    \end{mathparpagebreakable}
    Predicative W types only allow $U$ to be $\Set$ or $\Type{}$,
    while impredicative W types also allow it to be $\Prop$.
    Including impredicative W types as well poses several technical challenges.% to the realisability semantics.
\end{itemize}

Because some of these changes violate backward compatibility, they cannot be
adopted in \lang.

The literature suggests that future work could prove \langAnother and \lang
equivalent to derive that strong normalization (and therefore logical
consistency) of \langAnother implies that they hold in \lang.
More specifically, \cite{conversion} show that a typed and an untyped convertibility in a Martin--L\"of type theory (MLTT) imply each other;
and \citet{whynotW, polynomial-functors-w} show that W types in MLTT with propositional equality
can encode well-formed inductive types, including nested inductive types.

We leave this line of inquiry as future work\footnote{In fact, ongoing work by
  the second author, Yufeng Li, in collaboration with Bruno Barras has reportedly
  finished the strong normalization proof of \langAnother using realisability
  candidates based on work by \citet{barras-thesis}. (Private
  communication, Dec. 2021).}, since we have other reasons to believe backward-incompatible
  changes are necessary in \lang to make sized typing practical.
Nevertheless, we next explain where each of these changes originate and why they
seem necessary for the model.

\subsubsection{Typed Reduction}

Recall from \autoref{sec:overview:comparison} that we add an impredicative $\Prop$ universe
and universe cumulativity to the existing universe hierarchy in \CIChatminus.
We follow the set-theoretical model presented by \citet{not-so-simple-cc},
where $\Prop$ is treated proof-irrelevantly:
its set-theoretical interpretation is the set $\set{\emptyset, \set{\emptyset}}$,
and a type in $\Prop$ is either $\set{\emptyset}$ (representing true, inhabitated propositions)
or $\emptyset$ (representing false, uninhabited propositions).

Impredicativity of function types is encoded using a \emph{trace encoding} \citep{aczel-trace}.
First, the \emph{trace} of a (set-theoretical) function $f : A \to B$ is defined as
$$\trace(f) = \set{(a, b) \mid a \in A, b \in f(a)}.$$
Then the interpretation of a function type $\prod{x}{t}{u}$ is defined as
$$\bigg\{\trace(f) \mathbin{\big|} f \in A \times \bigcup_{a \in A} B_a \text{ and } \forall a \in A, f(a) \in B_a\bigg\}$$
where $A$ is the interpretation of $t$ and $B_a$ is the interpretation of $u$ when $x = a$,
while a function $\abs{x}{t}{e}$ is interpreted as
$\set{(a, b) \mid a \in A, b \in y_a}$
where $y_a$ is the interpretation of $e$ when $x = a$.

To see that this definition satisfies impredicativity,
suppose that $u$ is in $\Prop$.
Then $B_a$ is either $\emptyset$ or $\set{\emptyset}$.
If it is $\emptyset$, then there is no possible $f(a)$,
making the interpretation of the function type itself $\emptyset$.
If it is $\set{\emptyset}$, then $f(a) = \emptyset$,
and $\trace(f) = \emptyset$ since there is no $b \in f(a)$,
making the interpretation of the function type itself $\set{\emptyset}$.

Since reduction is untyped, it is perfectly fine for ill-typed terms to reduce.
For instance, we can have the derivation
$\mt, \mt \vdash \app{(\abs{x}{(\prod{p}{\Prop}{p \to p})}{x})}{\Prop} \rhd_\beta \Prop$
even though the left-hand side is not well typed.
However, to justify a convertibility (such as a reduction) in the model,
we need to show that the set-theoretic interpretations of both sides are equal.
For the example above, since $\prod{p}{\Prop}{p \to p}$ is in $\Prop$
and is inhabited by $\abs{p}{\Prop}{\abs{x}{p}{x}}$,
its interpretation must be $\set{\emptyset}$.
Then the interpretation of the function on the left-hand side must be $\set{(\emptyset, \emptyset)}$.
By the definition of the interpretation of application,
since the interpretation of $\Prop$ is not in the domain of the function,
the left-hand side becomes $\emptyset$.
Meanwhile, the right-hand side is $\set{\emptyset, \set{\emptyset}}$,
and the interpretations of the two sides aren't equal.

Ultimately, the set-theoretic interpretations of terms only make sense for well-typed terms,
despite being definable for ill-typed ones as well.
Therefore, to ensure a sensible interpretation,
reduction (and therefore subtyping and convertibility) needs to be typed.

\subsubsection{Size Irrelevance}

In the model, we need to know that functions cannot make computational decisions
based on the value of a size variable, \ie that computation is size irrelevant.
This is necessary to model functions as set-theoretic functions, since sizes are
ordinals and (set-theoretic) functions quantifying over ordinals may be too
large to be proper sets.

In short, while we conjecture that size irrelevance holds in \lang since size
expressions are second class and size variables are implicitly quantified, it is
no longer true in the model, where sizes are modelled as ordinals and size
variables must be explicitly quantified.
As a result, we follow \citet{barras-thesis} in creating two typing modes in
\langAnother (normal and size irrelevant) and two function spaces (normal
and sized) which allow proving that functions respect sizes in necessary
situations in the model.
The sized function space and size irrelevant mode enforce that the size of the
function's domain is irrelevant during typing, and this is used to type check
fixpoints.

In detail, the problem arises as follows.

Given a recursive call $f$ of some fixpoint whose body is $e'$
and two functions $\psi_1, \psi_2$ of the same type as $f$,
if they behave identically, then the model requires that
$\subst{e'}{f}{\psi_1}$ and $\subst{e'}{f}{\psi_2}$ are indistinguishable.
However, this cannot be shown with the current typing rules,
which is why \emph{size irrelevance} is introduced.

Formally, the set-theoretic model interprets terms and types as their natural
set-theoretic counterparts and size expressions as ordinals;
we call these their \emph{valuations}.
Given some environment $\Gamma$ and a term $e$ that is well typed under
$\Gamma$ with size variables $V = \SV(e)$,
letting $\rho$ be the valuations of the term variables of $\Gamma$ and $\pi$ be
the valuations of the size variables in $V$,
the valuation of $e$ is denoted by $\Val(e)_\rho^\pi$.

Consider now the valuation of the following term that is well typed under
$\Gamma$.
$$e = \fixE{\upsilon}{f}{\Nat^\upsilon \rightarrow \Nat^\upsilon}{e'}{\infty}$$
As the fixpoint is evaluated at the infinite size $\infty$,
intuitively the valuation of $e$ must be the fixed point of
$e'$ with respect to $f$.
Then to compute $e$, we take an initial approximation of $e'$ and iterate until
the fixed point has been reached.

For simplicity, suppose that for every ordinal $\alpha$, we have some valuation
$\Val(\Nat^\upsilon)_\rho^{\subst{\pi}{\upsilon}{\alpha}} = \McN^\alpha$,
where given some ordered ordinals $\vec{\alpha}$,
$\vec{\McN^{\alpha}}$ is a $\subseteq$-increasing sequence of sets constant
beyond $\alpha = \omega$.
%
Let $D_0 = \set{\emptyset}$, the vacuous function space
(representing $\McN^0 \to \McN^0$),
and define the following:
%
\begin{align*}
  D_\alpha
  &= \Val(\Nat^\upsilon \rightarrow \Nat^\upsilon)_\rho^{\subst{\pi}{\upsilon}{\alpha}}
  = \McN^\alpha \rightarrow \McN^\alpha \\
  \varphi_\alpha(\psi) &= \Val(e')_{\subst{\rho}{f}{\psi}}^{\subst{\pi}{\upsilon}{\alpha}}
  \qquad (\text{where} ~ \psi \in D_\alpha)
\end{align*}

The usual approach to compute $\Val(e)_\rho^\pi$ is to iterate up to the least fixed point of
$\varphi_\alpha$ starting at $\psi_0 = D_0$ and setting
$\psi_{\alpha + 1} = \varphi_\alpha(\psi_\alpha)$.
\refrule{fix-explicit} ensures that $\psi_\alpha \in D_\alpha$;
however, we also need to ensure that the sequence
$\vec{\psi_\alpha}$ eventually converges.

What would be a sufficient condition for convergence?  As
$\vec{\psi_\alpha}$ is obtained by successively improving upon
approximations of the fixed point of (the interpretation of) the
defining body $e'$, we expect that subsequent approximations to use
the results of previous approximations, and so that
\begin{align*}
  \forall x \in \McN^\alpha \subseteq \McN^\beta, \psi_\alpha(x) = \psi_\beta(x).
  \label{eqn:irrel}\tag{\textsc{irrel}}
\end{align*}
This is the formal statement of size irrelevance in the model:
size variables bound by fixpoints merely restrict their domains and don't
affect their computation.
It turns out that size irrelevance ensures that $\psi_\alpha$
converges at $\psi_\omega$,
so it suffices to prove \eqref{eqn:irrel}.

We proceed by induction on $\alpha$ and $\beta$.
Assuming \eqref{eqn:irrel} holds for some $\alpha$ and $\beta$,
unfolding definitions, the goal is to show that
%
$$\forall x \in \McN^{\alpha+1} \subseteq \McN^{\beta+1},
  \Val(e')_{\subst{\rho}{f}{\psi_\alpha}}^{\subst{\pi}{\upsilon}{\alpha}}(x) =
  \Val(e')_{\subst{\rho}{f}{\psi_\beta}}^{\subst{\pi}{\upsilon}{\beta}}(x).$$
%
Inductively, $\psi_\alpha$ and $\psi_\beta$ behave identically,
but from \refrule{fix-explicit} we cannot easily conclude that $e'$ cannot tell
them apart.
This is the same problem encountered by \citet{barras-thesis},
who resolves it using a new size irrelevant judgement.
We use a similar judgement for \langAnother,
expanding it to allow recursive references of fixpoints as arguments
to other functions.

\subsubsection{Size-Annotated Fixpoints}

As shown above, the set-theoretic interpretation of a fixpoint evaluated at some size $s$
is the iteration of its corresponding operator up to $\alpha$ times,
where $\alpha$ is the valuation of $s$.
Without explicitly annotating the size, we wouldn't know how many times to iterate,
since $s$ is otherwise only found in the type of the fixpoint and not in the fixpoint term itself.

\iffalse
\subsubsection{Interpretation of the Infinite Size}

An additional challenge in constructing the set-theoretic model is
the justification of $\mu$-reduction, which seems to require
the ordinal interpretation of the infinite size $\infty$.
Consider for instance the fixpoint
$e = \fixE{\upsilon}{f}{\Nat^\upsilon \rightarrow \Nat^\upsilon}{e'}{\infty}$
but instantiated to the $\infty$ size and applied to $\Zero$.
Then $\app{e}{\Zero}$ $\mu$-reduces as follows:
$$\app{\fixE{\upsilon}{f}{\Nat^\upsilon \rightarrow \Nat^\upsilon}{e'}{\infty}}{\Zero}
\rhd_\mu
\app{\subst{\subst{e'}{\upsilon}{\infty}}{f}{e}}{\Zero}$$
Let $\pi$ and $\rho$ be size and term variable valuations,
define $\psi_\alpha$ as above, and recall that if $\alpha \geq \omega$,
then $\psi_\alpha = \psi_\omega$.
Suppose then that we have an ordinal $\kappa \geq \omega$ such that we have
$\psi_{\kappa+1} = \psi_\kappa = \psi_\omega = \Val(e)_\rho^\pi$.
To justify $\mu$-reduction, we need to show the following holds:
$$\Val(\app{e}{\Zero})_\rho^\pi = \Val(\app{\subst{\subst{e'}{\upsilon}{\infty}}{f}{e}}{\Zero})_\rho^\pi$$
Let $\mathcal{O} = \Val(\Zero)_\rho^\pi$.
On the left-hand side, we have
\begin{align*}
  \Val(\app{e}{\Zero})_\rho^\pi &= \Val(e)_\rho^\pi ~ \mathcal{O} \\
  &= \psi_{\kappa}(\mathcal{O}) \\
  &= \psi_{\kappa+1}(\mathcal{O}) &\text{since $\kappa \geq \omega$} \\
  &= \phi_\kappa(\psi_\kappa)(\mathcal{O}) &\text{expanding $\psi_{\kappa+1}$} \\
  &= \Val(e')_{\subst{\rho}{f}{\psi_\kappa}}^{\subst{\pi}{\upsilon}{\kappa}} ~ \mathcal{O} &\text{by definition}
\end{align*}
Meanwhile, on the right-hand side,
\begin{align*}
  \Val(\app{\subst{\subst{e'}{\upsilon}{\infty}}{f}{e}}{\Zero})_\rho^\pi
  &= \Val(\subst{\subst{e'}{\upsilon}{\infty}}{f}{e})_\rho^\pi ~ \mathcal{O} \\
  &= \Val(\subst{e'}{\upsilon}{\infty})_{\subst{\rho}{f}{\psi_\kappa}}^\pi ~ \mathcal{O} &\text{by substitutivity}
\end{align*}

Then all we need to show is that
$\Val(e')_{\subst{\rho}{f}{\psi_\kappa}}^{\subst{\pi}{\upsilon}{\kappa}}
= \Val(\subst{e'}{\upsilon}{\infty})_{\subst{\rho}{f}{\psi_\kappa}}^\pi$,
moving the substitution by $\infty$ into the valuation as $\kappa$.
More generally, for any term $e$ along with valuations $\pi$, $\rho$,
one would like to have ordinal $\Infty(e; \upsilon)_\rho^\pi$ such that the
following infinite-size subsitutivity property holds:
$$\forall \kappa \geq \Infty(e; \upsilon)_\rho^\pi,
  \Val(e)_{\rho}^{\subst{\pi}{\upsilon}{\kappa}}
  = \Val(\subst{e}{\upsilon}{\infty})_{\rho}^{\pi}$$

This equality expresses the idea that $\Infty(e;\upsilon)_\rho^\pi$
closes off all inductive types annotated with $\upsilon$ in $e$, so
$\Infty(e;\upsilon)_\rho^\pi$ is the denotation of $\infty$ for $\upsilon$ in
$M$ under $\rho$ and $\pi$.
%
Intuitively, we know this ordinal $\Infty(e;\upsilon)_\rho^\pi$ exists,
because the strict positivity condition ensures that by iterating the
operator associated with an inductive type up to its closure ordinal,
we eventually reach their fixpoints.
%
Since there can only be finitely many inductive types in $e$, an
ordinal with the infinite-size substitutivity property is the
supremum of these closure ordinals.

However, the actual situation is more complicated.
%
To see the complication, let us first consider the case where we want to compute
$\Infty(\prod{x}{A}{B};\upsilon)_\rho^\pi$.
%
The infinite-size substitutivity property requires that for
$\kappa \geq \Infty(\prod{x}{A}{B};\upsilon)_\rho^\pi$,
%
\begin{align*}
  \Val(\prod{x}{A}{B})_\rho^{\subst{\pi}{\upsilon}{\kappa}} =
  \Val(\prod{x}{\subst{A}{\upsilon}{\infty}}{\subst{B}{\upsilon}{\infty}};\upsilon)_\rho^\pi
\end{align*}
%
which is just
%
\begin{align*}
  \setprod_{a \in \Val(A)_\rho^{\subst{\pi}{\upsilon}{\kappa}}}
  {\Val(B)_{\subst{\rho}{x}{a}}^{\subst{\pi}{\upsilon}{\kappa}}}
  =
  \setprod_{a \in \Val(\subst{A}{\upsilon}{\infty})_\rho^\pi}
  {\Val(\subst{B}{\upsilon}{\infty})_{\subst{\rho}{x}{a}}^{\pi}}
\end{align*}
%
Inductively, $\kappa \geq \Infty(A;\upsilon)$ means we have equality of domains:
$\Val(A)_\rho^{\subst{\pi}{\upsilon}{\kappa}} = \Val(\subst{A}{\nu}{\infty})_\rho^\pi$.
%
So it just remains to show % equality of each codomain (\todo: ``each
%codomain'' somehow sounds funny, better to say ``each fibre''?)
$\Val(B)_{\subst{\rho}{x}{a}}^{\subst{\pi}{\upsilon}{\kappa}} =
\Val(\subst{B}{\upsilon}{\infty})_{\subst{\rho}{x}{a}}^{\pi}$, where
$a$ ranges over
$a \in \Val(A)_\rho^{\subst{\pi}{\upsilon}{\kappa}} =
\Val(\subst{A}{\nu}{\infty})_\rho^\pi$.
%
And so by induction we want
$\kappa \geq \Infty(A;\upsilon)_{\subst{\rho}{x}{a}}^\pi$ for each
$a$.
%
This shows that we can take
%
\begin{align*}
  \Infty(\prod{x}{A}{B};\upsilon)_\rho^\pi =
  \sup_{a \in \Val(\subst{A}{\upsilon}{\infty})_\rho^\pi}\{
  \Infty(A;\upsilon)_\rho^\pi, \Infty(B;\upsilon)_{\subst{\rho}{x}{a}}^\pi
  \}
\end{align*}

The key to note here is that we have taken the supremum of an infinite set.
%
In general, to compute $\Infty(e;\upsilon)_\rho^\pi$, despite
$\upsilon$ only appearing in finitely many places, it may not be
sufficient to take the supremum (maximum) of a finite set of ordinals.
%
In fact, in the above calculation, we have taken the supremum of (at
most) $\card{\Val(\subst{A}{\upsilon}{\infty})_\rho^\pi}+1$ many
ordinals, and the value of $\prod{x}{A}{B}$ also depends on (at most)
$\card{\Val(\subst{A}{\upsilon}{\infty})_\rho^\pi}+1$ many values.
%
(\todo: this example of $\Pi$ is really just to first give a simple
intuition on how computing $\Infty$ needs to take into account the
dependencies of different $\Infty$s. Not sure if this example is
helping anything.)

One now considers the case where one is computing
$\Infty(e;\upsilon)_\rho^\pi$ for
$e = \fixE{\upsilon}{f}{\Nat^\nu \rightarrow \Nat^\nu}{e'}{s}$.
%
Put $\kappa$ an ordinal and take each $\phi(\kappa)_\alpha$ as the
$\alpha$-th iteration of the operator
$\Val(e')_{\subst{\rho}{f}{-}}^{\subst{\subst{\pi}{\upsilon}{\kappa}}{\nu}{\alpha}}
=
\Val(e')_{\subst{\rho}{f}{-}}^{\subst{\subst{\pi}{\nu}{\alpha}}{\upsilon}{\kappa}}$
so that
$\Val(e)_\rho^{\subst{\pi}{\upsilon}{\kappa}} =
\lim_\alpha \phi(\kappa)_\alpha$.
%
Let each $\psi_\alpha$ be the $\alpha$-th iteration of
$\Val(\subst{e'}{\upsilon}{\infty})_{\subst{\rho}{f}{-}}^{\subst{\pi}{\nu}{\alpha}}$
so that
$\Val(\subst{e}{\upsilon}{\infty})_\rho^{\pi} =
\lim_\alpha \psi_\alpha$.
%
The property of infinite-size substitutivity then says
$\lim_\alpha \phi(\kappa)_\alpha = \lim_\alpha \psi_\alpha$
for large $\kappa$.
%
This is somewhat reminiscent of the $\Pi$-types situation, where we
wanted each codomain (\todo: fibre) to be equal.
%
Here, we might want each $\phi(\kappa)_\alpha=\psi_\alpha$,
which is the same as saying
$\Val(e')_{\subst{\rho}{f}{-}}^{\subst{\subst{\pi}{\nu}{\alpha}}{\upsilon}{\kappa}}
=
\Val(\subst{e'}{\upsilon}{\infty})_{\subst{\rho}{f}{-}}^{\subst{\pi}{\nu}{\alpha}}$.
%
Clearly, for fixed $\alpha$ this is possible for
$\kappa \geq \Infty(e';\upsilon)_{\subst{\rho}{f}{-}}^{\subst{\pi}{\nu}{\alpha}}$.
%
In the $\Pi$ case we took the supremum of the $\Infty$s over the
domain.
%
But in this case if one were to do the same thing, one would
do $\sup_{\alpha \in \Ord}
{\Infty(e';\upsilon)_{\subst{\rho}{f}{-}}^{\subst{\pi}{\nu}{\alpha}}}$.
%
Since $\Ord$ is a proper class, the resulting supremum is not
necessarily an ordinal, unless
$\Infty(e';\upsilon)_{\subst{\rho}{f}{-}}^{\subst{\pi}{\nu}{\alpha}}$
is constant for $\alpha \geq \beta$ for some $\beta$.

However, taking a closer look, we see that $\alpha$ is the
interpretation of the size $\nu$.
%
So when $\alpha$ and $\kappa$ are both large, it is reasonable to
expect
$\phi(\kappa)_\alpha
\Val(e')_{\subst{\rho}{f}{-}}^{\subst{\subst{\pi}{\nu}{\alpha}}{\upsilon}{\kappa}}
=
\Val(\subst{\subst{e'}{\upsilon}{\infty}}{\nu}{\infty})_{\subst{\rho}{f}{-}}^{\pi}$
and
$\psi_\alpha =
\Val(\subst{e'}{\upsilon}{\infty})_{\subst{\rho}{f}{-}}^{\subst{\pi}{\nu}{\alpha}}
=
\Val(\subst{\subst{e'}{\upsilon}{\infty}}{\nu}{\infty})_{\subst{\rho}{f}{-}}^{\pi}$.
%
And so one sees that one has pushed both $\nu,\upsilon$ to $\infty$.
%
Formalising the idea, it turns out that the key to the solution of
computing the $\infty$ size is to compute
$\Infty(e;\upsilon{\upsilon_i}_{i=1}^n)_\rho^\pi$ for a set of size
variables.
%
That is, we compute an ordinal
$\Infty(e;\upsilon{\upsilon_i}_{i=1}^n)_\rho^\pi$ such that
if each $\kappa_i \geq \Infty(e;\{\upsilon_i\}_{i=1}^n)_\rho^\pi$
then
$\Val(\subst{e}{\upsilon_i}{\infty}_{i=1}^n)_\rho^\pi
=
\Val(e)_\rho^{\subst{\pi}{\upsilon_i}{\kappa_i}_{i=1}^n}$.
\fi

%%% Local Variables:
%%% TeX-master: "../main.tex"
%%% TeX-engine: default
%%% End:
