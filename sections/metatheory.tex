\section{Metatheoretical Results}
\label{sec:metatheory}

In this section, we describe the metatheory of \lang.
Some of the metatheory is inherited or essentially similar to past work~\citep{cic-hat-minus,cc-hat-omega,cic-hat},
although we must adapt key proofs to account for differences in subtyping and definitions.
Complete proofs for a language like \lang are too involved to present in full,
so we provide only key lemmas and proof sketches.

In short, \lang satisfies confluence and subject reduction, with the same caveats as in CIC for cofixpoints.
Proofs of strong normalization and logical consistency for \lang remain future work.
We conjecture how the proofs of strong normalization and consistency should proceed based on past work~\citep{cic-hat-minus,cc-hat-omega,cic-hat}.

\subsection{Confluence}

Recall that we define $\rhd$ as the congruent closure of \reduction and $\rhd^*$ as the reflexive--transitive closure of $\rhd$.

\begin{theorem}[Confluence]
\label{thm:metatheory:confluence}
  If $\gg \vdash e \rhd^* e_1$ and $\gg \vdash e \rhd^* e_2$,
  then there is some term $e'$ such that $\gg \vdash e_1 \rhd^* e'$ and $\gg \vdash e_2 \rhd^* e'$.
\end{theorem}

\begin{proof}[{[sketch]}]
  We use the Takahashi translation technique due to \citet{takahashitrans},
  which is a simplification of the standard parallel reduction technique.
  It uses the Takahashi translation $e^\dagger$ of terms $e$,
  defined as the simultaneous single-step reduction of all
  $\beta\zeta\delta\Delta\iota\mu\nu$-redexes of $e$ in left-most inner-most order.
  The proof is relatively standard thanks to reduction being purely syntactic.
  % Is it though?
\end{proof}

\subsection{Subject Reduction}
\label{sec:meta:sub-red}

Suject reduction does not hold in \lang or in Coq due to the way coinductives are presented.
This is a well-known problem, discussed previously in a sized-types setting by \citet{cc-hat-omega},
on which our presentation of coinductives is based,
as well as by the Coq developers\footnote{The discussion of the problem and suggested solutions can be found here: \url{https://github.com/coq/coq/issues/5288/}.}.

In brief, the current presentation of coinductives requires that cofixpoint reduction be \textit{restricted},
\ie occurring only when it is the target of a case expression.
This allows for strong normalization of cofixpoints in much the same way restricting fixpoint reduction to when the recursive argument is syntactically a fully-applied constructor does.
One way this can break subject reduction is by making the type of a case expression not be convertible before and after the cofixpoint reduction.
As a concrete example, consider the following coinductive definition for conaturals.
\begin{displaymath}
  \defn{\Conat}{\Type{}}{\assm{\Succ}{\Conat \to \Conat}}
\end{displaymath}
For some motive $P$ and branch $e$, we have the following $\nu$-reduction.
\begin{align*}
  &\caseof*{\erase{P}}{\cofix*{1}{\defn{\omega}{\Conat}{\app{\Succ}{\omega}}}}{\seq{\Succ \Rightarrow e}} \rhd_\nu \\
  &\caseof*{\erase{P}}{\app{\Succ}{(\cofix*{1}{\defn{\omega}{\Conat}{\app{\Succ}{\omega}}})}}{\seq{\Succ \Rightarrow e}}
\end{align*}
Assuming both terms are well-typed, the former has type $\app{P}{(\cofix*{1}{\defn{\omega}{\Conat}{\app{\Succ}{\omega}}})}$ while the latter has type $\app{P}{(\app{\Succ}{(\cofix*{1}{\defn{\omega}{\Conat}{\app{\Succ}{\omega}})}})}$, but for an arbitrary $P$ these are not convertible without allowing cofixpoints to reduce arbitrarily.

\begin{figure}
  \fbox{$\gg \vdash e \reduce_{\beta\zeta\delta\Delta\iota\mu\nu'} e$} \hfill
  \vspace{-3ex}
  \begin{align*}
    \dots & \\
    \gg \vdash q_m & \reduce_{\nu'} \substvec{e_m}{f_k}{q_k} \\
    \textit{where} ~ & \forall i \in \vec{k}, q_i \equiv \cofix{i}{f_k}{t_k}{e_k}
  \end{align*}
  \caption{Reduction rules with unrestricted cofixpoint reduction}
  \label{fig:reduction-alt}
\end{figure}

On the other hand, if we do allow unrestricted $\nu$-reduction as in \autoref{fig:reduction-alt}, subject reduction does hold.

\begin{theorem}[Subject Reduction]
  \label{thm:metatheory:sr}
  Let $\Sigma$ be a well-formed signature.
  Suppose that $\nu$-reduction to allows unrestricted reduction of cofixpoints.
  Then $\gg \vdash e : t$ and $e \rhd e'$ implies $\gg \vdash e' : t$.
\end{theorem}

\begin{proof}[{[sketch]}]
  By induction on $\gg \vdash e : t$.  Most cases are straightforward,
  making use of confluence when necessary, such as for a lemma of
  $\Pi$-injectivity to handle $\beta$-reduction in \refrule{app}.
  %
  The case for \refrule{case} where $e \rhd e'$ by $\iota$-reduction relies on the fact that
  if $x$ is the name of a \coinductive type and appears strictly positively in $t$,
  then $x$ appears covariantly in $t$.
  (This is only true without nested \coinductive types, which \lang disallows in well-formed signatures.)

  The case for \refrule{case} and $e$ (guarded) $\nu$-reduces to $e'$ requires an unrestricted $\nu$-reduction.
  After guarded $\nu$-reduction, the target (a cofixpoint) appears in the motive unguarded by a case expression, but must be unfolded to re-establish typing the type $t$.
\end{proof}

\subsubsection{The Problem with Nested Inductives}

\newcommand{\nat}{\const{N}}

Recall from \autoref{sec:typing} that we disallow nested \coinductive types.
This means that when defining a \coinductive type, it cannot recursively appear as the parameter of another type.
For instance, the following definition $\nat$, while equivalent to $\Nat$,
is disallowed due to the appearance of $\nat$ as a parameter of $\Box$.
\begin{align*}
  \defn{\nat}{\Type{}}{\seq{\assm{\Zero}{\nat}, \assm{\Succ}{\app{\Box}{\nat} \to \nat}}}
\end{align*}
Notice that we have the subtyping relation $\nat^\upsilon \leq \nat^{\hat{\upsilon}}$,
but by convertibility of parameters,
we do \emph{not} have $\app{\Box^\infty}{\nat^\upsilon} \leq \app{\Box^\infty}{\nat^{\hat{\upsilon}}}$.
This convertibility due to the removal of polarity annotations on \coinductive definitions is what allows us to retain backward compatibility.
But because case expressions on some target $\nat^{\hat{s}}$ force recursive arguments to have size $s$ exactly,
and the target also has type $\nat^{\hat{\hat{s}}}$ by cumulativity,
the argument of $\Succ$ could have both type $\app{\Box^\infty}{\nat^s}$ and $\app{\Box^\infty}{\nat^{\hat{s}}}$, violating convertibility.
We can exploit this fact and break subject reduction explicitly with the following counterexample term.
\begin{displaymath}
\begin{array}{l}
  \caseof*{\erase{\abs{\any}{\nat}{\nat^\infty}}}{\app{\Succ}{(\app{\MkBox}{\nat^{\hat{\upsilon}}}{\Zero})}}{\\
  \seq{\Zero \Rightarrow \Zero,\\
  \phantom{\langle} \Succ \Rightarrow \app{(\abs{A}{\Type{}}{\abs{x}{A}{\Zero}})}{(\app{\Box^\infty}{\nat^{\hat{\hat{\upsilon}}}})}}}
\end{array}
\end{displaymath}
By cumulativity, the target can be typed as $\nat^{\hat{\upsilon}^{3}}$ (that is, with size $\hat{\hat{\hat{\upsilon}}}$).
By \refrule{case}, the second branch must then have type $\prod{x}{\app{\Box}{\nat^{\hat{\hat{\upsilon}}}}}{\nat^\infty}$ --- and so it does.
Then the case expression is well typed with type $\nat^\infty$.
However, once we reduce the the case expression, we end up with a term that is no longer well typed.
\begin{displaymath}
  \app{(\abs{A}{\Type{}}{\abs{x}{A}{\Zero}})}
    {(\app{\Box^\infty}{\nat^{\hat{\hat{\upsilon}}}})}
    {(\app{\MkBox}{\nat^{\hat{\upsilon}}}{\Zero})}
\end{displaymath}
By \refrule{app}, the second argument should have type $\app{\Box^\infty}{\nat^{\hat{\hat{\upsilon}}}}$ (or a subtype thereof), but it cannot:
the only type the second argument can have is $\app{\Box^\infty}{\nat^{\hat{\upsilon}}}$.

There are several possible solutions, all threats to backward compatibility.
\CIChat's solution is to require that constructors be fully-applied and that their parameters be bare terms,
so that we are forced to write $\app{\MkBox}{\nat}{\Zero}$.
The problem with this is that Coq treats constructors essentially like functions,
and assuring that they are fully applied with bare parameters would require either reworking how they are represented internally
or adding an intermediate step to elaborate partially-applied constructors into functions whose bodies are fully-applied constructors.
The other solution, as mentioned, is to add polarities back in, so that $\Box$ with positive polarity in its parameter yields the subtyping relation $\app{\Box^\infty}{\nat^{\hat{\upsilon}}} \leq \app{\Box^\infty}{\nat^{\hat{\hat{\upsilon}}}}$.

Interestingly, because the implementation infers all size annotations from a completely bare program,
our counterexample and similar ones exploiting explicit size annotations aren't directly expressible,
and don't appear to be generated by the algorithm, which would solve for the smallest size annotations.
For the counterexample, in the second branch, the size annotation would be (a size constrained to be equal to) $\hat{\upsilon}$.
We conjecture that the terms synthesized by the inference algorithm do indeed satisfy subject reduction even in the presence of nested \coinductives,
although perhaps at the expense of other desired metatheoretical properties,
such as completeness of the algorithm with respect to the typing rules,
which we discuss in the next subsection.

\subsection{Strong Normalization and Logical Consistency}

Our ultimate goal and primary future work is to prove strong normalization and logical consistency of \lang.

\begin{conjecture}[Strong Normalization]\label{thm:metatheory:sn}
  %
  If $\gg \vdash e : t$ then $e$ contains no infinite
  reduction sequences.
  %
\end{conjecture}

\begin{conjecture}[Logical Consistency]\label{thm:metatheory:lc}
  %
  The type $\prod{p}{\Prop}{p}$ is uninhabited in \lang.
  %
\end{conjecture}


Taking inspiration from \citet{cic-hat-minus,cc-hat-omega,cic-hat},
we conjecture that these statements can be proven using the
$\Lambda$-set technique from \citet{lambda-set-altenkrich,lambda-set-pts}.
Our proof attempt is still ongoing.

However, with coinduction and cofixpoints, results from \citet{cc-hat-omega}
suggest that subject reduction and strong
normalization may not be true at the same time, because subject
reduction appears to require unrestricted unfolding of cofixpoints,
which breaks normalization.

Recall that Coq itself is not strongly normalizing, only weakly normalizing.\footnote{At least, the underlying calculus is not. The counterexample ``normalizes'' to a stack overflow on machine with finite memory.}

\begin{minted}{coq}
Definition cbv_omega := fix f (n : nat) := let x := f n in O.
\end{minted}

This is a side-effect of relaxing the guard condition to enable more sound programs to type check.
Ideally, sufficiently expressive sized typing will allow us to replace the guard condition entirely and regain strong normalization in Coq.

However, an intermediate goal may be to achieve only weak normalization.
This would also maintain backward compatibility with Coq, although it is unclear if counterexamples like the above are ever desired in user programs.

%%% Local Variables:
%%% TeX-master: "../main.tex"
%%% TeX-engine: default
%%% End:
