\section{Metatheoretical Results}
\label{sec:metatheory}

In this section, we describe the metatheory of \lang.
Some of the metatheory is inherited or essentially similar to past work~\citep{cic-hat-minus,cc-hat-omega,cic-hat},
although we must adapt key proofs to account for differences in subtyping and definitions.
Complete proofs for a language like \lang are too involved to present in full,
so we provide only key lemmas and proof sketches.

In short, \lang satisfies confluence and subject reduction, with the same caveats as in CIC for cofixpoints.
Proofs of strong normalization and logical consistency for \lang remain future work.
% TODO: Why a conjecture and not a proof? Because it hard.
We conjecture how the proofs of strong normalization and consistency should proceed based on past work~\citep{cic-hat-minus,cc-hat-omega,cic-hat}.

\subsection{Confluence}

Recall that we define $\rhd$ as the congruent closure of \reduction and $\rhd^*$ as the reflexive--transitive closure of $\rhd$.

\begin{theorem}[Confluence]
\label{thm:metatheory:confluence}
  If $\gg \vdash e \rhd^* e_1$ and $\gg \vdash e \rhd^* e_2$,
  then there is some term $e'$ such that $\gg \vdash e_1 \rhd^* e'$ and $\gg \vdash e_2 \rhd^* e'$.
\end{theorem}

\begin{proof}[{[sketch]}]
  We use the Takahashi translation technique due to \citet{takahashitrans},
  which is a simplification of the standard parallel reduction technique.
  It uses the Takahashi translation $e^\dagger$ of terms $e$,
  defined as the simultaneous single-step reduction of all
  $\beta\zeta\delta\Delta\iota\mu\nu$-redexes of $e$ in left-most inner-most order.
  The proof is relatively standard thanks to reduction being purely syntactic and untyped.
  % Is it though?
\end{proof}

\subsection{Subject Reduction}
\label{sec:metatheory:sub-red}

Suject reduction does not hold in \lang or in Coq due to the way coinductives are presented.
This is a well-known problem, discussed previously in a sized-types setting by \citet{cc-hat-omega},
on which our presentation of coinductives is based,
as well as by the Coq developers\footnote{The discussion of the problem and suggested solutions can be found here: \url{https://github.com/coq/coq/issues/5288/}.}.

In brief, the current presentation of coinductives requires that cofixpoint reduction be \textit{restricted},
\ie occurring only when it is the target of a case expression.
This allows for strong normalization of cofixpoints in much the same way restricting fixpoint reduction to when the recursive argument is syntactically a fully-applied constructor does.
One way this can break subject reduction is by making the type of a case expression not be convertible before and after the cofixpoint reduction.
As a concrete example, consider the following coinductive definition for conaturals.
\begin{displaymath}
  \seq{\assm{\Conat}{\Type{}}} \coloneqq {\seq{\assm{\Succ}{\Conat \to \Conat}}}
\end{displaymath}
For some motive $P$ and branch $e$, we have the following $\nu$-reduction.
\begin{align*}
  &\caseof*{\erase{P}}{\cofix*{1}{\defn{\omega}{\Conat}{\app{\Succ}{\omega}}}}{\seq{\Succ \Rightarrow e}} \rhd_\nu \\
  &\caseof*{\erase{P}}{\app{\Succ}{(\cofix*{1}{\defn{\omega}{\Conat}{\app{\Succ}{\omega}}})}}{\seq{\Succ \Rightarrow e}}
\end{align*}
Assuming both terms are well-typed, the former has type $\app{P}{(\cofix*{1}{\defn{\omega}{\Conat}{\app{\Succ}{\omega}}})}$ while the latter has type $\app{P}{(\app{\Succ}{(\cofix*{1}{\defn{\omega}{\Conat}{\app{\Succ}{\omega}})}})}$, but for an arbitrary $P$ these are not convertible without allowing cofixpoints to reduce arbitrarily.

\begin{figure}
  \fbox{$\gg \vdash e \reduce_{\beta\zeta\delta\Delta\iota\mu\nu'} e$} \hfill
  \vspace{-3ex}
  \begin{align*}
    \dots & \\
    \gg \vdash q_m & \reduce_{\nu'} \substvec{e_m}{f_k}{q_k} \\
    \textit{where} ~ & \forall i \in \vec{k}, q_i \equiv \cofix{i}{f_k}{t_k}{e_k}
  \end{align*}
  \caption{Reduction rules with unrestricted cofixpoint reduction}
  \label{fig:reduction-alt}
\end{figure}

On the other hand, if we do allow unrestricted $\nu$-reduction as in \autoref{fig:reduction-alt}, subject reduction does hold,
at the expense of normalization,
as a cofixpoint on its own could reduce indefinitely.

\begin{theorem}[Subject Reduction]
  \label{thm:metatheory:sr}
  Let $\Sigma$ be a well-formed signature.
  Suppose that $\nu$-reduction to allows unrestricted reduction of cofixpoints.
  Then $\gg \vdash e : t$ and $e \rhd e'$ implies $\gg \vdash e' : t$.
\end{theorem}

\begin{proof}[{[sketch]}]
  By induction on $\gg \vdash e : t$.  Most cases are straightforward,
  making use of confluence when necessary, such as for a lemma of
  $\Pi$-injectivity to handle $\beta$-reduction in \refrule{app}.
  %
  The case for \refrule{case} where $e \rhd e'$ by $\iota$-reduction relies on the fact that
  if $x$ is the name of a \coinductive type and appears strictly positively in $t$,
  then $x$ appears covariantly in $t$.
  (This is only true without nested \coinductive types, which \lang disallows in well-formed signatures.)

  The case for \refrule{case} and $e$ (guarded) $\nu$-reduces to $e'$ requires an unrestricted $\nu$-reduction.
  After guarded $\nu$-reduction, the target (a cofixpoint) appears in the motive unguarded by a case expression, but must be unfolded to re-establish typing the type $t$.
\end{proof}

\subsubsection{The Problem with Nested Inductives}

\newcommand{\nat}{\const{N}}

Recall from \autoref{sec:typing} that we disallow nested \coinductive types.
This means that when defining a \coinductive type, it cannot recursively appear as the parameter of another type.
For instance, the following definition $\nat$, while equivalent to $\Nat$,
is disallowed due to the appearance of $\nat$ as a parameter of $\Box$.
\begin{align*}
  \seq{\assm{\nat}{\Type{}}} \coloneqq \seq{\assm{\Zero}{\nat}, \assm{\Succ}{\app{\Box}{\nat} \to \nat}}
\end{align*}
Notice that we have the subtyping relation $\nat^\upsilon \leq \nat^{\hat{\upsilon}}$,
but as all parameters are invariant for backward compatibility and need to be convertible,
we do \emph{not} have $\app{\Box^\infty}{\nat^\upsilon} \leq \app{\Box^\infty}{\nat^{\hat{\upsilon}}}$.
But because case expressions on some target $\nat^{\hat{s}}$ force recursive arguments to have size $s$ exactly,
and the target also has type $\nat^{\hat{\hat{s}}}$ by cumulativity,
the argument of $\Succ$ could have both type $\app{\Box^\infty}{\nat^s}$ and $\app{\Box^\infty}{\nat^{\hat{s}}}$, violating convertibility.
We exploit this fact and break subject reduction explicitly with the following counterexample term.
\begin{displaymath}
\begin{array}{l}
  \caseof*{\erase{\abs{\any}{\nat}{\nat^\infty}}}{\app{\Succ}{(\app{\MkBox}{\nat^{\hat{\upsilon}}}{\Zero})}}{\\
  \seq{\Zero \Rightarrow \Zero,\\
  \phantom{\langle} \Succ \Rightarrow \app{(\abs{A}{\Type{}}{\abs{x}{A}{\Zero}})}{(\app{\Box^\infty}{\nat^{\hat{\hat{\upsilon}}}})}}}
\end{array}
\end{displaymath}
By cumulativity, the target can be typed as $\nat^{\hat{\upsilon}^{3}}$ (that is, with size $\hat{\hat{\hat{\upsilon}}}$).
By \refrule{case}, the second branch must then have type $\prod{x}{\app{\Box}{\nat^{\hat{\hat{\upsilon}}}}}{\nat^\infty}$ --- and so it does.
Then the case expression is well typed with type $\nat^\infty$.
However, once we reduce the the case expression, we end up with a term that is no longer well typed.
\begin{displaymath}
  \app{(\abs{A}{\Type{}}{\abs{x}{A}{\Zero}})}
    {(\app{\Box^\infty}{\nat^{\hat{\hat{\upsilon}}}})}
    {(\app{\MkBox}{\nat^{\hat{\upsilon}}}{\Zero})}
\end{displaymath}
By \refrule{app}, the second argument should have type $\app{\Box^\infty}{\nat^{\hat{\hat{\upsilon}}}}$ (or a subtype thereof), but it cannot:
the only type the second argument can have is $\app{\Box^\infty}{\nat^{\hat{\upsilon}}}$.

There are several possible solutions, all threats to backward compatibility.
\CIChat's solution is to require that constructors be fully-applied and that their parameters be bare terms,
so that we are forced to write $\app{\MkBox}{\nat}{\Zero}$.
The problem with this is that Coq treats constructors essentially like functions,
and assuring that they are fully applied with bare parameters would require either reworking how they are represented internally
or adding an intermediate step to elaborate partially-applied constructors into functions whose bodies are fully-applied constructors.
The other solution, as mentioned, is to add polarities back in, so that $\Box$ with positive polarity in its parameter yields the subtyping relation $\app{\Box^\infty}{\nat^{\hat{\upsilon}}} \leq \app{\Box^\infty}{\nat^{\hat{\hat{\upsilon}}}}$.

Interestingly, because the implementation infers all size annotations from a completely bare program,
our counterexample and similar ones exploiting explicit size annotations aren't directly expressible,
and don't appear to be generated by the algorithm, which would solve for the smallest size annotations.
For the counterexample, in the second branch, the size annotation would be (a size constrained to be equal to) $\hat{\upsilon}$.
We conjecture that the terms synthesized by the inference algorithm do indeed satisfy subject reduction even in the presence of nested \coinductives
by being a strict subset of all well-typed terms that excludes counterexamples like the above.

\subsubsection{Bareness of Type Annotations}\label{sec:metatheory:sr:bare}

As mentioned in \autoref{sec:typing:syntax}, type annotations on functions and let expressions
as well as case expression motives and \cofixpoint types
need to be bare terms (or position terms, for the latter) to maintain subject reduction.
To see why, suppose they were not bare, and consider the term
$\app{(\fix*{1}{\defn{f^1}{\Nat^\tau \rightarrow \Nat^\tau}{\abs{n}{\Nat^{\succ{\tau}}}{n}}})}{(\app{\Succ}{\Zero})}$.
Under empty environments, the fixpoint argument is well-typed with type $\Nat^{\succ{\succ{s}}}$ for any size expression $s$,
while the fixpoint itself is well-typed with type $\Nat^{r} \rightarrow \Nat^{r}$ for any size expression $r$.
For the application to be well-typed, it must be that $r$ is $\succ{\succ{s}}$,
and the entire term has type $\Nat^{\succ{\succ{s}}}$.

By the $\mu$-reduction rule, this steps to the term $\app{(\abs{n}{\Nat^{\succ{\tau}}}{n})}{(\app{\Succ}{\Zero})}$.
Unfortunately, the term is no longer well-typed, as $\app{\Succ}{\Zero}$ cannot be typed with type $\Nat^{\succ{\tau}}$ as is required.
By erasing the type annotation of the function,
there is no longer a restriction on what size the function argument must have,
and subject reduction is no longer broken.
An alternate solution is to substitute $\tau$ for $\succ{s}$ during $\mu$-reduction,
but this requires typed reduction to know what the correct size to substitute is,
violating backward compatibility with Coq,
whose reduction and convertibility rules are untyped.

\subsection{Strong Normalization and Logical Consistency}\label{sec:metatheory:sn}

Following strong normalization and logical consistency for \CIChatminus and \CChatomega,
we conjecture that they hold for \lang as well.

\begin{conjecture}[Strong Normalization]\label{thm:metatheory:sn}
  %
  If $\gg \vdash e : t$ then $e$ contains no infinite
  reduction sequences.
  %
\end{conjecture}

\begin{conjecture}[Logical Consistency]\label{thm:metatheory:lc}
  %
  There is no $e$ such that $\mt, \mt \vdash e : \prod{p}{\Prop}{p}$.
  %
\end{conjecture}

Note that strong normalization is a stricter requirement than Coq, which is only \emph{weakly} normalizing:
every well-typed term has \emph{some} finite reduction sequence.
This relaxation enables more programs to pass the guard predicates while still being consistent.
For instance, the first fixpoint definition is accepted, as \texttt{x} is never used,
but the second is not.

\begin{minted}{coq}
Fixpoint f (u: unit): unit := let x := f u in tt.
Fail Fixpoint f (u: unit): False := let x := f u in x.
\end{minted}

\subsubsection{Proof Attempts}

In ongoing work%
\footnote{To be submitted as an undergraduate thesis by Yufeng Li under the supervision of Bruno Barras.}
on a variant of \lang called \langAnother,
strong normalization has been proven with a set-theoretic model construction
equipped with realisability candidates based on \citet{barras-thesis}.
To simplify the presentation, \langAnother does not deal with mutual fixpoints,
cofixpoints, local definitions, or global declarations;
for the proof to work, \langAnother requires additional nontrivial changes relative to \lang:

\begin{itemize}
  \item Reduction, subtyping, and conversion are typed.
    That is, each judgement requires the type of the terms,
    and the derivation rules may have as typing judgements as premises.
  \item Fixpoint type annotations require explicit size annotations
    (\ie are no longer merely position terms),
    explicitly abstract over a size variable,
    and are explicitly applied to a size expression.
    The typing rule no longer erases the type, and the size in the fixpoint type is fixed.
    \begin{mathparpagebreakable}
      \inferrule*[right=\defrule{fix-explicit}]
      { \Gamma (f : t) \vdash e : \subst{t}{\upsilon}{\succ{\upsilon}} }
      { \Gamma \vdash \fixE{\upsilon}{f}{t}{e}{s} : \subst{t}{\upsilon}{s}}
    \end{mathparpagebreakable}
    The reduction rule adds an additional substitution of the predecessor of the size expression,
    in line with how $f$ may only be called in $e$ with a smaller size.
    \begin{mathparpagebreakable}
      \Gamma \vdash \app{\fixE{\upsilon}{f}{t}{e}{\succ{s}}\,}{\vec{b}}{(\app{c_\ell}{\vec{p}}{\vec{a}})}
      \rhd_\mu \app{\subst{\subst{e}{\upsilon}{s}}{f}{\fixE{\upsilon}{f}{t}{e}{s}}}{\vec{b}}{(\app{c_\ell}{\vec{p}}{\vec{a}})}
    \end{mathparpagebreakable}
  \item Rather than inductive definitions in general, only predicative W types are considered.
    W types can be defined as an inductive type:
    \begin{mathparpagebreakable}
      \seq{\app{\W}{(\assm{A}{U})}{(\assm{B}{A \rightarrow U})}} \coloneqq
      \seq{\assm{\Sup}{(\assm{a}{A}) \rightarrow (\assm{b}{\app{B}{a} \rightarrow \app{\W}{A}{B}}) \rightarrow \app{\W}{A}{B}}}
    \end{mathparpagebreakable}
    Predicative W types only allow $U$ to be $\Set$ or $\Type{}$,
    while impredicative W types also allow it to be $\Prop$.
    Including impredicative W types as well poses several technical challenges to the realisability semantics.
  \item A new size-irrelevant typing judgement is needed, similar to that introduced by \citet{barras-thesis}.
\end{itemize}

Because these changes violate backward compatibility, they cannot be adopted in \lang.
The current literature suggests that \langAnother and \lang may be proven to be equivalent
such that strong normalization (and therefore logical consistency) of \langAnother implies that they hold in \lang.
More specifically, \cite{conversion} show that a typed and an untyped convertibility in a Martin--L\"of type theory (MLTT) imply each other;
and \citet{w-types, polynomial-functors-w} show that W types in an extensional MLTT
can encode well-formed inductive types, including nested inductive types
(while \citet{hofmann} shows that extensional MLTT is a conservative extension of intensional MLTT).

\subsubsection{Size-Irrelevance}
%
Via this model construction, the main lesson learnt is
that the intuition about how size types ensure termination by
restricting recursion on smaller elements is perhaps not quite so
straightforward to capture set-theoretically.

Take the situation of \eqref{eqn:fix-example} as example.
%
In the strong normalization model, we interpret terms and types as
their natural set-theoretic counterparts and size variables as
ordinals.
%
For $\rho$ a valuation of $\Gamma$ mapping variables to sets and $\pi$
mapping size variables to ordinals, denote by $\Val(M)_\rho^\pi$ the
set-theoretic denotation of the term $M$ under these valuations.
%
Now, suppose $s=\infty$ and consider how one would define
$\Val(F)_\rho^\pi$.
%
Since $s=\infty$, intuitively, $F$ should be the fixpoint of $e$.
%
So, we take some initial approximation of the fixpoint of the value of
$e$ and at every stage, improve the approximation by evaluating $e$ on
the prior approximation, until the approximation cannot be further
improved, which means we have reached a fixpoint of the iteration.

For the sake of simplicity, assume that for all ordinals $\alpha$, the
value of $\Nat^\upsilon$ where $\upsilon$ is interpreted as $\alpha$
is just
$\Val(\Nat^\upsilon)_\rho^{\subst{\pi}{\upsilon}{\alpha}} =
\McN^\alpha$ where $(\McN^\alpha)_\alpha$ is an $\subseteq$-increasing
family sets constant beyond $\omega$.
%
Putting $D_0$ to be some well-chosen singleton set and
$D_\alpha \triangleq \Val(\Nat^\upsilon \to
\Nat^\upsilon)_\rho^{\subst{\pi}{\upsilon}{\alpha}} = \McN^\alpha \to
\McN^\alpha$, the usual approach is to iterate up until the least
fixpoint of the operator
%
\begin{align*}
  \varphi \triangleq
  (\alpha \in \Ord) \mapsto (\psi \in D_\alpha) \mapsto \Val(e)_{\subst{\rho}{f}{\psi}}^{\subst{\pi}{\upsilon}{\alpha}}
  \tag{$e$-iter}\label{eqn:e-iter}
\end{align*}
%
starting from the initial approximation $\varphi_0 \in D_0$ and
setting the $(\alpha+1)$-th approximation $\varphi_{\alpha+1}$ as
$\varphi(\varphi_\alpha)$.
%
The typing rule for $F$ given by \refrule{fix-explicit} is sufficient
to ensure that each $\varphi_\alpha \in D_\alpha$.
%
However, this alone is not enough: we want the sequence
$(\varphi_\alpha)_\alpha$ to be convergent.

What would be a sufficient condition for convergence?
%
Note that $(\varphi_\alpha)_\alpha$ is obtained by successively
improving upon approximations of the fixpoint of $\varphi$, so one
would expect that
%
\begin{align*}
  \varphi_\alpha(x) = \varphi_\beta(x) \text{ for all } x \in \McN^\alpha \subseteq \McN^\beta
  \label{eqn:size-irrel}\tag{\textsc{size-irrel}}
\end{align*}
%
This expresses a condition of size-irrelevance: size variables bound
by fixpoint recursors can only be used to restrict their domains, and
should not be used to affect the value of computation.
%
And it turns out that \eqref{eqn:size-irrel} is enough to ensure
$(\varphi_\alpha)_\alpha$ converges to $\varphi_\omega$.
%
So, it remains to prove \eqref{eqn:size-irrel}.
%
Assume inductively it holds $\alpha,\beta$ and we would like to prove
it for $\alpha+1,\beta+1$, so that the goal is to show, for
$x \in \McN^{\alpha+1} \subseteq \McN^{\beta+1}$,
%
\begin{align*}
  \Val(e)_{\subst{\rho}{f}{\varphi_\alpha}}^{\subst{\pi}{\upsilon}{\alpha}}(x) =
  \Val(e)_{\subst{\rho}{f}{\varphi_\beta}}^{\subst{\pi}{\upsilon}{\beta}}(x)
\end{align*}
%
By the intuitive understanding of sized typing, on input
$x \in \McN^{\alpha+1}$ of size $\alpha+1$, the body $e$ can only
recursively call $f$ on inputs of size at most $\alpha$.
%
And inductively, $\varphi_\alpha$ behaves identically to
$\varphi_\beta$ on inputs of size at most $\alpha$.
%
So, $e$ on input $x \in \McN^{\alpha+1}$ should not be able to
distinguish between $\varphi_\alpha$ and $\varphi_\beta$, thus
ensuring the above equality.
%
However, just from \refrule{fix-explicit}, it seems that one cannot
easily conclude that $e$ cannot tell apart $\varphi_\alpha$ and
$\varphi_\beta$.

This problem was encountered also by \citet{barras-thesis}, who solved
it by introducing a special typing mode called size-irrelevance typing
and syntactic marker for the $\Pi$-types of fixpoint recursors.
%
We have used a similar solution to get around this problem in the
strong normalization proof of the alternative formulation of \lang.
%
However, in the size-irrelevance typing of \citet{barras-thesis},
there was the requirement that fixpoint recursors can never occur as
arguments to other functions in their defining body.
%
For example, in order for $e$ to pass size-irrelevance typing, $e$
cannot contain a sub-expression of the form $(\app{M}{f})$.
%
We were able to get rid of this requirement in the strong
normalization proof of this alternative formulation of \lang.
%
In fact, the typing rules allowed for size-irrelevance typing can be
expanded to include counterparts for almost all of the ``normal''
typing rules.

An alternative approach seems to be to use a model involving PERs,
where the PERs are designed to ensure size-irrelevance.
%
In any case, it seems that an inherent restriction of size-irrelevance
is one may not have a recursive function $F$ with behaviours such as
$\app{F}{n} \approx \Nat^\upsilon \to ...n\text{ times}... \to
\Nat^\upsilon$ or even $\app{F}{n} \approx \Nat^\upsilon$ where
$\upsilon$ is the size variable bound by $F$.
%
\citet{cic-hat-minus} has a similar restriction present in
\CIChatminus, and this restriction matches the intuition of
size-irrelevance.
%
If $\app{F}{n} \approx \Nat^\upsilon$ then the value of $F$ on an
input $n$ depends on the size $\upsilon$, which precisely the
behaviour size-irrelevance aims to forbid.
%
On the other hand, $\app{F}{n} \approx \Nat^\infty \to
...n\text{ times}...\to\Nat^\infty$ does adhere to size-irrelevance.

\subsubsection{Computation of $\infty$}
%
In the set-theoretic model, we also discovered that giving a
set-theoretic interpretation of the $\infty$ size was more technically
involved than one would expect.

Take the $\mu$-reduction equation in \eqref{eqn:mu-example} as an
example.
%
Once again, assume $s=\infty$ and \eqref{eqn:size-irrel} holds, so that
$(\varphi_\alpha)_\alpha$ is constant beyond $\omega$.
%
Then, by the previous discussion, the value of $F$ and of
$\left\{\kw{fix}^\upsilon ~ f : \Nat^\upsilon \to \Nat^\upsilon
  \coloneqq e\right\}_{s}$ are both taken to be
$\varphi_\omega = \varphi_{\kappa}$ for all $\kappa \geq \omega$.
%
Then, by substitutivity, the $\mu$-reduction equation in
\eqref{eqn:mu-example} should say, for sufficiently large
$\kappa \geq \omega$,
%
\begin{align*}
  \Val(\app{F}{t})_\rho^\pi =
  \Val(\app{\subst{\subst{e}{\upsilon}{\infty}}{f}{
  \left\{\kw{fix}^\upsilon ~ f : \Nat^\upsilon \to \Nat^\upsilon \coloneqq e\right\}_{\infty}
  }}{t})_\rho^\pi
\end{align*}
%
By substitutivity, this is equivalent to showing that
%
\begin{align*}
  \varphi_{\kappa+1}(\Val(t)_\rho^\pi) =
  \Val(\subst{e}{\upsilon}{\infty})_{\subst{\rho}{f}{\varphi_\kappa}}^{\pi}(\Val(t)_\rho^\pi)
\end{align*}
%
But
$\varphi_{\kappa+1} =
\Val(e)_{\subst{\rho}{f}{\varphi_\kappa}}^{\subst{\pi}{\upsilon}{\kappa}}$,
to show the above equality, it remains to move the
$\subst{e}{\nu}{\infty}$ in the syntax into the valuation
$\subst{\pi}{\nu}{\kappa}$, for some large $\kappa$.

More generally, it seems true that for all terms $M$ and valuations
$\rho$ and $\pi$, and size variables $\nu$, there is some ordinal
$\Infty(M;\nu)_\rho^\pi$ with the $\infty$-substitutivity property:
%
\begin{align*}
  \kappa \geq \Infty(M;\nu)_\rho^\pi \text{ implies }
  \Val(\subst{M}{\nu}{\infty})_\rho^\pi = \Val(M)_\rho^{\subst{\pi}{\nu}{\kappa}}
  \label{eqn:infty-subst}\tag{$\infty$-subst}
\end{align*}
%
This equality somehow expresses the idea that $\Infty(M;\nu)_\rho^\pi$
closes off all inductive types annotated with $\nu$ in $M$, so
$\Infty(M;\nu)_\rho^\pi$ is the denotation of $\infty$ for $\nu$ in
$M$ under $\rho$ and $\pi$.
%
Intuitively, we know this ordinal $\Infty(M;\nu)_\rho^\pi$ exists,
because the strict positivity condition ensures that by iterating the
operator associated with an inductive type up to its closure ordinal,
we eventually reach their fixpoints.
%
Since there can only be finitely many inductive types in $M$, an
ordinal with the $\infty$-substitutivity property is just the
supremum of these closure ordinals.

However, the computation of $\Infty(M;\nu)_\rho^\pi$ is complicated by
the fact that in $M$, the size variable $\nu$ can be annotated to more
than one inductive type.
%
For example, in $M$, the size variable $\nu$ can be annotated to both
$\Nat^\nu$ and $I^\nu$, where $I$ is some inductive type with a
different closure ordinal than $\Nat$.
%
In fact, it turned out that computing $\Infty(M;\nu)_\rho^\pi$ was
much more involved than initially expected.

%%% Local Variables:
%%% TeX-master: "../main.tex"
%%% TeX-engine: default
%%% End:
