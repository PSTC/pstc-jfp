\section{Metatheoretical Results}
\label{sec:metatheory}

In this section, we describe the metatheory of \lang.
Some of the metatheory is inherited or essentially similar to past work~\citep{cic-hat-minus,cc-hat-omega,cic-hat},
although we must adapt key proofs to account for differences in subtyping and definitions.
Complete proofs for a language like \lang are too involved to present in full,
so we provide only key lemmas and proof sketches.

In short, \lang satisfies confluence and subject reduction, with the same caveats as in CIC for cofixpoints.
While strong normalization and logical consistency have been proven for a variant of \lang
with features that violate backward compatibility,
proofs for \lang itself remain future work.

\subsection{Confluence}

Recall that we define $\rhd$ as the congruent closure of \reduction and $\rhd^*$ as the reflexive--transitive closure of $\rhd$.

\begin{theorem}[Confluence]
\label{thm:metatheory:confluence}
  If $\gg \vdash e \rhd^* e_1$ and $\gg \vdash e \rhd^* e_2$,
  then there is some term $e'$ such that $\gg \vdash e_1 \rhd^* e'$ and $\gg \vdash e_2 \rhd^* e'$.
\end{theorem}

\begin{proof}[{[sketch]}]
  We use the Takahashi translation technique due to \citet{takahashitrans},
  which is a simplification of the standard parallel reduction technique.
  It uses the Takahashi translation $e^\dagger$ of terms $e$,
  defined as the simultaneous single-step reduction of all
  $\beta\zeta\delta\Delta\iota\mu\nu$-redexes of $e$ in left-most inner-most order.
  The proof is relatively standard thanks to reduction being purely syntactic and untyped.
  % Is it though?
\end{proof}

\subsection{Subject Reduction}
\label{sec:metatheory:sub-red}

Suject reduction does not hold in \lang or in Coq due to the way coinductives are presented.
This is a well-known problem, discussed previously in a sized-types setting by \citet{cc-hat-omega},
on which our presentation of coinductives is based,
as well as by the Coq developers\footnote{The discussion of the problem and suggested solutions can be found here: \url{https://github.com/coq/coq/issues/5288/}.}.

In brief, the current presentation of coinductives requires that cofixpoint reduction be \textit{restricted},
\ie occurring only when it is the target of a case expression.
This allows for strong normalization of cofixpoints in much the same way restricting fixpoint reduction to when the recursive argument is syntactically a fully-applied constructor does.
One way this can break subject reduction is by making the type of a case expression not be convertible before and after the cofixpoint reduction.
As a concrete example, consider the following coinductive definition for conaturals.
\begin{displaymath}
  \seq{\assm{\Conat}{\Type{}}} \coloneqq {\seq{\assm{\Succ}{\Conat \to \Conat}}}
\end{displaymath}
For some motive $P$ and branch $e$, we have the following $\nu$-reduction.
\begin{align*}
  &\caseof*{\erase{P}}{\cofix*{1}{\defn{\omega}{\Conat}{\app{\Succ}{\omega}}}}{\seq{\Succ \Rightarrow e}} \rhd_\nu \\
  &\caseof*{\erase{P}}{\app{\Succ}{(\cofix*{1}{\defn{\omega}{\Conat}{\app{\Succ}{\omega}}})}}{\seq{\Succ \Rightarrow e}}
\end{align*}
Assuming both terms are well-typed, the former has type $\app{P}{(\cofix*{1}{\defn{\omega}{\Conat}{\app{\Succ}{\omega}}})}$ while the latter has type $\app{P}{(\app{\Succ}{(\cofix*{1}{\defn{\omega}{\Conat}{\app{\Succ}{\omega}})}})}$, but for an arbitrary $P$ these are not convertible without allowing cofixpoints to reduce arbitrarily.

\begin{figure}
  \fbox{$\gg \vdash e \reduce_{\beta\zeta\delta\Delta\iota\mu\nu'} e$} \hfill
  \vspace{-3ex}
  \begin{align*}
    \dots & \\
    \gg \vdash q_m & \reduce_{\nu'} \substvec{e_m}{f_k}{q_k} \\
    \textit{where} ~ & \forall i \in \vec{k}, q_i \equiv \cofix{i}{f_k}{t_k}{e_k}
  \end{align*}
  \caption{Reduction rules with unrestricted cofixpoint reduction}
  \label{fig:reduction-alt}
\end{figure}

On the other hand, if we do allow unrestricted $\nu$-reduction as in \autoref{fig:reduction-alt}, subject reduction does hold,
at the expense of normalization,
as a cofixpoint on its own could reduce indefinitely.

\begin{theorem}[Subject Reduction]
  \label{thm:metatheory:sr}
  Let $\Sigma$ be a well-formed signature.
  Suppose that $\nu$-reduction to allows unrestricted reduction of cofixpoints.
  Then $\gg \vdash e : t$ and $e \rhd e'$ implies $\gg \vdash e' : t$.
\end{theorem}

\begin{proof}[{[sketch]}]
  By induction on $\gg \vdash e : t$.  Most cases are straightforward,
  making use of confluence when necessary, such as for a lemma of
  $\Pi$-injectivity to handle $\beta$-reduction in \refrule{app}.
  %
  The case for \refrule{case} where $e \rhd e'$ by $\iota$-reduction relies on the fact that
  if $x$ is the name of a \coinductive type and appears strictly positively in $t$,
  then $x$ appears covariantly in $t$.
  (This is only true without nested \coinductive types, which \lang disallows in well-formed signatures.)

  The case for \refrule{case} and $e$ (guarded) $\nu$-reduces to $e'$ requires an unrestricted $\nu$-reduction.
  After guarded $\nu$-reduction, the target (a cofixpoint) appears in the motive unguarded by a case expression, but must be unfolded to re-establish typing the type $t$.
\end{proof}

\subsubsection{The Problem with Nested Inductives}

\newcommand{\nat}{\const{N}}

Recall from \autoref{sec:typing} that we disallow nested \coinductive types.
This means that when defining a \coinductive type, it cannot recursively appear as the parameter of another type.
For instance, the following definition $\nat$, while equivalent to $\Nat$,
is disallowed due to the appearance of $\nat$ as a parameter of $\Box$.
\begin{align*}
  \seq{\assm{\app{\Box}{(\assm{A}{\Type{}})}}{\Type{}}} &\coloneqq \seq{\assm{\MkBox}{A \rightarrow \app{\Box}{A}}} \\
  \seq{\assm{\nat}{\Type{}}} &\coloneqq \seq{\assm{\Zero}{\nat}, \assm{\Succ}{\app{\Box}{\nat} \to \nat}}
\end{align*}
Notice that we have the subtyping relation $\nat^\upsilon \leq \nat^{\hat{\upsilon}}$,
but as all parameters are invariant for backward compatibility and need to be convertible,
we do \emph{not} have $\app{\Box^\infty}{\nat^\upsilon} \leq \app{\Box^\infty}{\nat^{\hat{\upsilon}}}$.
But because case expressions on some target $\nat^{\hat{s}}$ force recursive arguments to have size $s$ exactly,
and the target also has type $\nat^{\hat{\hat{s}}}$ by cumulativity,
the argument of $\Succ$ could have both type $\app{\Box^\infty}{\nat^s}$ and $\app{\Box^\infty}{\nat^{\hat{s}}}$, violating convertibility.
We exploit this fact and break subject reduction explicitly with the following counterexample term.
\begin{displaymath}
\begin{array}{l}
  \caseof*{\erase{\abs{\any}{\nat}{\nat^\infty}}}{\app{\Succ}{(\app{\MkBox}{\nat^{\hat{\upsilon}}}{\Zero})}}{\\
  \seq{\Zero \Rightarrow \Zero,\\
  \phantom{\langle} \Succ \Rightarrow \app{(\abs{A}{\Type{}}{\abs{x}{A}{\Zero}})}{(\app{\Box^\infty}{\nat^{\hat{\hat{\upsilon}}}})}}}
\end{array}
\end{displaymath}
By cumulativity, the target can be typed as $\nat^{\hat{\upsilon}^{3}}$ (that is, with size $\hat{\hat{\hat{\upsilon}}}$).
By \refrule{case}, the second branch must then have type $\prod{x}{\app{\Box}{\nat^{\hat{\hat{\upsilon}}}}}{\nat^\infty}$ --- and so it does.
Then the case expression is well typed with type $\nat^\infty$.
However, once we reduce the the case expression, we end up with a term that is no longer well typed.
\begin{displaymath}
  \app{(\abs{A}{\Type{}}{\abs{x}{A}{\Zero}})}
    {(\app{\Box^\infty}{\nat^{\hat{\hat{\upsilon}}}})}
    {(\app{\MkBox}{\nat^{\hat{\upsilon}}}{\Zero})}
\end{displaymath}
By \refrule{app}, the second argument should have type $\app{\Box^\infty}{\nat^{\hat{\hat{\upsilon}}}}$ (or a subtype thereof), but it cannot:
the only type the second argument can have is $\app{\Box^\infty}{\nat^{\hat{\upsilon}}}$.

There are several possible solutions, all threats to backward compatibility.
\CIChat's solution is to require that constructors be fully-applied and that their parameters be bare terms,
so that we are forced to write $\app{\MkBox}{\nat}{\Zero}$.
The problem with this is that Coq treats constructors essentially like functions,
and assuring that they are fully applied with bare parameters would require either reworking how they are represented internally
or adding an intermediate step to elaborate partially-applied constructors into functions whose bodies are fully-applied constructors.
The other solution, as mentioned, is to add polarities back in, so that $\Box$ with positive polarity in its parameter yields the subtyping relation $\app{\Box^\infty}{\nat^{\hat{\upsilon}}} \leq \app{\Box^\infty}{\nat^{\hat{\hat{\upsilon}}}}$.

Interestingly, because the implementation infers all size annotations from a completely bare program,
our counterexample and similar ones exploiting explicit size annotations aren't directly expressible,
and don't appear to be generated by the algorithm, which would solve for the smallest size annotations.
For the counterexample, in the second branch, the size annotation would be (a size constrained to be equal to) $\hat{\upsilon}$.
We conjecture that the terms synthesized by the inference algorithm do indeed satisfy subject reduction even in the presence of nested \coinductives
by being a strict subset of all well-typed terms that excludes counterexamples like the above.

\subsubsection{Bareness of Type Annotations}\label{sec:metatheory:sr:bare}

As mentioned in \autoref{sec:typing:syntax}, type annotations on functions and let expressions
as well as case expression motives and \cofixpoint types
need to be bare terms (or position terms, for the latter) to maintain subject reduction.
To see why, suppose they were not bare, and consider the term
$\app{(\fix*{1}{\defn{f^1}{\Nat^\tau \rightarrow \Nat^\tau}{\abs{n}{\Nat^{\succ{\tau}}}{n}}})}{(\app{\Succ}{\Zero})}$.
Under empty environments, the fixpoint argument is well-typed with type $\Nat^{\succ{\succ{s}}}$ for any size expression $s$,
while the fixpoint itself is well-typed with type $\Nat^{r} \rightarrow \Nat^{r}$ for any size expression $r$.
For the application to be well-typed, it must be that $r$ is $\succ{\succ{s}}$,
and the entire term has type $\Nat^{\succ{\succ{s}}}$.

By the $\mu$-reduction rule, this steps to the term $\app{(\abs{n}{\Nat^{\succ{\tau}}}{n})}{(\app{\Succ}{\Zero})}$.
Unfortunately, the term is no longer well-typed, as $\app{\Succ}{\Zero}$ cannot be typed with type $\Nat^{\succ{\tau}}$ as is required.
By erasing the type annotation of the function,
there is no longer a restriction on what size the function argument must have,
and subject reduction is no longer broken.
An alternate solution is to substitute $\tau$ for $\succ{s}$ during $\mu$-reduction,
but this requires typed reduction to know what the correct size to substitute is,
violating backward compatibility with Coq,
whose reduction and convertibility rules are untyped.

\subsection{Strong Normalization and Logical Consistency}\label{sec:metatheory:sn}

Following strong normalization and logical consistency for \CIChatminus and \CChatomega,
we conjecture that they hold for \lang as well.

\begin{conjecture}[Strong Normalization]\label{thm:metatheory:sn}
  %
  If $\gg \vdash e : t$ then $e$ contains no infinite
  reduction sequences.
  %
\end{conjecture}

\begin{conjecture}[Logical Consistency]\label{thm:metatheory:lc}
  %
  There is no $e$ such that $\mt, \mt \vdash e : \prod{p}{\Prop}{p}$.
  %
\end{conjecture}

Note that strong normalization is a stricter requirement than Coq, which is only \emph{weakly} normalizing:
every well-typed term has \emph{some} finite reduction sequence.
This relaxation enables more programs to pass the guard predicates while still being consistent.
For instance, the first fixpoint definition is accepted, as \texttt{x} is never used,
but the second is not.

\begin{minted}{coq}
Fixpoint f (u: unit): unit := let x := f u in tt.
Fail Fixpoint f (u: unit): False := let x := f u in x.
\end{minted}

\subsubsection{Proof Attempt}

In ongoing work%
\footnote{To be submitted as an undergraduate thesis by Yufeng Li under the supervision of Bruno Barras.}
on a variant of \lang called \langAnother,
strong normalization has been proven with a set-theoretic model construction
equipped with realisability candidates based on \citet{barras-thesis}.
To simplify the presentation, \langAnother does not deal with mutual fixpoints,
cofixpoints, local definitions, or global declarations.
For the proof to work, it requires additional nontrivial changes relative to \lang:

\begin{itemize}
  \item As is the case for most set-theoretic models,
    reduction, subtyping, and convertibility are typed.
    That is, each judgement requires the type of the terms,
    and the derivation rules may have as typing judgements as premises.
  \item Fixpoint type annotations require explicit size annotations
    (\ie are no longer merely position terms),
    explicitly abstract over a size variable,
    and are explicitly applied to a size expression.
    The typing rule no longer erases the type, and the size in the fixpoint type is fixed.
    \begin{mathparpagebreakable}
      \inferrule*[right=\defrule{fix-explicit}]
      { \Gamma (f : t) \vdash e : \subst{t}{\upsilon}{\succ{\upsilon}} }
      { \Gamma \vdash \fixE{\upsilon}{f}{t}{e}{s} : \subst{t}{\upsilon}{s}}
    \end{mathparpagebreakable}
    The fixpoint above binds the size variable $\upsilon$ in $t$ and in $e$.
    The reduction rule adds an additional substitution of the predecessor of the size expression,
    in line with how $f$ may only be called in $e$ with a smaller size.
    \begin{mathparpagebreakable}
      \Gamma \vdash \app{\fixE{\upsilon}{f}{t}{e}{\succ{s}}\,}{\vec{b}}{(\app{c_\ell}{\vec{p}}{\vec{a}})}
      \rhd_\mu \app{\subst{\subst{e}{\upsilon}{s}}{f}{\fixE{\upsilon}{f}{t}{e}{s}}}{\vec{b}}{(\app{c_\ell}{\vec{p}}{\vec{a}})}
    \end{mathparpagebreakable}
  \item Rather than inductive definitions in general, only predicative W types are considered.
    W types can be defined as an inductive type:
    \begin{mathparpagebreakable}
      \seq{\app{\W}{(\assm{A}{U})}{(\assm{B}{A \rightarrow U})}} \coloneqq
      \seq{\assm{\Sup}{(\assm{a}{A}) \rightarrow (\assm{b}{\app{B}{a} \rightarrow \app{\W}{A}{B}}) \rightarrow \app{\W}{A}{B}}}
    \end{mathparpagebreakable}
    Predicative W types only allow $U$ to be $\Set$ or $\Type{}$,
    while impredicative W types also allow it to be $\Prop$.
    Including impredicative W types as well poses several technical challenges to the realisability semantics.
  \item A new size irrelevant typing judgement is needed, similar to that introduced by \citet{barras-thesis}.
\end{itemize}

Because these changes violate backward compatibility, they cannot be adopted in \lang.
The current literature suggests that \langAnother and \lang may be proven to be equivalent
such that strong normalization (and therefore logical consistency) of \langAnother implies that they hold in \lang.
More specifically, \cite{conversion} show that a typed and an untyped convertibility in a Martin--L\"of type theory (MLTT) imply each other;
and \citet{w-types, polynomial-functors-w} show that W types in an extensional MLTT
can encode well-formed inductive types, including nested inductive types
(while \citet{hofmann} shows that extensional MLTT is a conservative extension of intensional MLTT).

Nevertheless, in the subsequent subsubsections we explain where these changes originate from
and why they are necessary for the model.

\subsubsection{Typed Reduction}

Recall from \autoref{sec:overview:comparison} that we add an impredicative $\Prop$ universe
and universe cumulativity to the existing universe hierarchy in \CIChatminus.
To handle this addition, we follow the set-theoretical model presented by \citet{not-so-simple-cc},
where $\Prop$ is treated proof-irrelevantly:
its set-theoretical interpretation is the set $\set{\set{\emptyset}, \emptyset}$,
and a type in $\Prop$ is either $\set{\emptyset}$ (representing true, inhabitated propositions)
or $\emptyset$ (representing false, uninhabited propositions).

To handle impredicativity of function types, they are encoded using a \emph{trace encoding} \citep{aczel-trace}.
First, the \emph{trace} of a (set-theoretical) function $f : A \to B$ is defined as
$$\trace(f) = \set{(a, b) \mid a \in A, b \in f(a)}.$$
Then the interpretation of a function type $\prod{x}{t}{u}$ is defined as
$$\bigg\{\trace(f) \mathbin{\big|} f \in A \times \bigcup_{a \in A} B_a \text{ and } \forall a \in A, f(a) \in B_a\bigg\}$$
where $A$ is the interpretation of $t$ and $B_a$ is the interpretation of $u$ when $x = a$,
while a function $\abs{x}{t}{e}$ is interpreted as
$$\set{(a, b) \mid a \in A, b \in B_a}$$
where $b$ is the interpretation of $e$ when $x = a$.

To see that this definition satisfies impredicativity,
suppose that $u$ is in $\Prop$.
Then $B_a$ is either $\emptyset$ or $\set{\emptyset}$.
If it is $\emptyset$, then there is no possible $f(a)$,
making the interpretation of the function type itself $\emptyset$.
If it is $\set{\emptyset}$, then $f(a) = \emptyset$,
and $\trace(f) = \emptyset$ since there is no $b \in f(a)$,
making the interpretation of the function type itself $\set{\emptyset}$.

Since reduction is untyped, it is perfectly fine for ill-typed terms to reduce.
For instance, we can have the derivation
$\mt, \mt \vdash \app{(\abs{x}{(\prod{p}{\Prop}{p \to p})}{x})}{\Prop} \rhd_\beta \Prop$
even though the left-hand side is not well typed.
However, to justify a convertibility (such as a reduction) in the model,
we need to show that the set-theoretic interpretations of both sides are equal.
For the example above, since $\prod{p}{\Prop}{p \to p}$ is in $\Prop$
and is inhabited by $\abs{p}{\Prop}{\abs{x}{p}{x}}$,
its interpretation must be $\set{\emptyset}$.
Then the interpretation of the function on the left-hand side must be $\set{(\emptyset, \emptyset)}$.
By the definition of the interpretation of application,
since the interpretation of $\Prop$ is not in the domain of the function,
the left-hand side becomes $\emptyset$.
Meanwhile, the right-hand side is $\set{\emptyset}$,
and the interpretations of the two sides are not equal.

% I want to mention why the interpretation of application yields the empty set for senseless things
% but it's starting to feel like we're digging too deep into the set-theoretic details...
% Basically the trace encoding erases the domain, so you can't even look out for cases
% where the domain doesn't line up with the argument.

Ultimately, the set-theoretic interpretations of terms only make sense for well-typed terms,
despite being definable for ill-typed ones as well.
Therefore, to ensure that the interpretation is sensible,
reduction (and therefore subtyping and convertibility) needs to be typed.

\subsubsection{Size-Annotated Fixpoints}

\todo

\subsubsection{Size Irrelevance}

Given a recursive call $f$ of some fixpoint whose body is $e'$
and two functions $\psi_1, \psi_2$ of the same type as $f$,
if they behave identically, then the model requires that
$\subst{e'}{f}{\psi_1}$ and $\subst{e'}{f}{\psi_2}$ are indistinguishable.
However, this cannot be shown with the current typing rules,
which is why \emph{size irrelevance} is introduced.

Formally, the set-theoretic model interpret terms and types as their natural
set-theoretic counterparts and size expressions as ordinals;
we call these their \emph{valuations}.
Given some environment $\Gamma$ and a term $e$ that is well typed under
$\Gamma$ with size variables $V = \SV(e)$,
letting $\rho$ be the valuations of the term variables of $\Gamma$ and $\pi$ be
the valuations of the size variables in $V$,
the valuation of $e$ is denoted by $\Val(e)_\rho^\pi$.

Consider now the valuation of the following term that is well typed under
$\Gamma$.
$$e = \fixE{\upsilon}{f}{\Nat^\upsilon \rightarrow \Nat^\upsilon}{e'}{\infty}$$
As the fixpoint is evaluated at the infinite size $\infty$,
intuitively the valuation of $e$ must be the fixed point of
$e'$ with respect to $f$.
Then to compute $e$, we take an initial approximation of $e'$ and iterate until
the fixed point has been reached.

For simplicity, suppose that for every ordinal $\alpha$, we have some valuation
$\Val(\Nat^\upsilon)_\rho^{\subst{\pi}{\upsilon}{\alpha}} = \McN^\alpha$,
where given some ordered ordinals $\vec{\alpha}$,
$\vec{\McN^\alpha}$ is a $\subseteq$-increasing sequence of sets constant
beyond $\alpha = \omega$.
%
Let $D_0$ be some well-chosen singleton set, which is often taken to
be the singleton empty set (in general, its sole inhabitant is
something that belongs to the values of all stages of the inductive
type recursion is happening on)
(\todo: Which? With what properties?)
(\todo: Is this explanation fine?)
and define the following:
%
\begin{align*}
  D_\alpha
  &= \Val(\Nat^\upsilon \rightarrow \Nat^\upsilon)_\rho^{\subst{\pi}{\upsilon}{\alpha}}
  = \McN^\alpha \rightarrow \McN^\alpha \\
  \varphi_\alpha(\psi) &= \Val(e')_{\subst{\rho}{f}{\psi}}^{\subst{\pi}{\upsilon}{\alpha}}
  \qquad (\text{where} ~ \psi \in D_\alpha)
\end{align*}

The usual approach to compute $\Val(e)_\rho^\pi$ is to iterate up to the least fixed point of
$\varphi_\alpha$ starting at $\psi_0 = D_0$ and setting
$\psi_{\alpha + 1} = \varphi_\alpha(\psi_\alpha)$.
\refrule{fix-explicit} ensures that $\psi_\alpha \in D_\alpha$;
however, we also need to ensure that for successive $\alpha$,
$\psi_\alpha$ eventually converges.

What would be a sufficient condition for convergence?  As
$\psi_\alpha$ is obtained by successively improving upon
approximations of the fixed point of $\varphi$, we expect that
subsequent approximations to use the results of previous
approximations.
%
(\todo: Why?)
(\todo: Does this explain it?)
%
So, we would expect:
%
\begin{align*}
  \forall x \in \McN^\alpha \subseteq \McN^\beta, \psi_\alpha(x) = \psi_\beta(x)
  \label{eqn:irrel}\tag{\textsc{irrel}}
\end{align*}
This is the formal statement of size irrelevance:
size variables bound by fixpoints merely restrict their domains and do not
affect their computation.
It turns out that size irrelevance ensures that $\psi_\alpha$
converges at $\psi_\omega$,
so it suffices to prove \eqref{eqn:irrel}.

We proceed by induction on $\alpha$ and $\beta$.
Assuming \eqref{eqn:irrel} holds for some $\alpha$ and $\beta$,
unfolding definitions, the goal is to show that
%
$$\forall x \in \McN^{\alpha+1} \subseteq \McN^{\beta+1},
  \Val(e')_{\subst{\rho}{f}{\psi_\alpha}}^{\subst{\pi}{\upsilon}{\alpha}}(x) =
  \Val(e')_{\subst{\rho}{f}{\psi_\beta}}^{\subst{\pi}{\upsilon}{\beta}}(x)$$
%
Inductively, $\psi_\alpha$ and $\psi_\beta$ behave identically,
but from \refrule{fix-explicit} we cannot easily conclude that $e'$ cannot tell
them apart.
This is the same problem encountered by \citet{barras-thesis},
who resolves it using a new size-irrelevant judgement.
We use a similar judgement for \langAnother,
expanding it to allow recursive references of fixpoints as arguments
to other functions.

\iffalse
This problem was encountered also by \citet{barras-thesis}, who solved
it by introducing a special typing mode called size-irrelevance typing
and syntactic marker for the $\Pi$-types of fixpoint recursors.
%
We have used a similar solution to get around this problem in the
strong normalization proof of the alternative formulation of \lang.
%
However, in the size-irrelevance typing of \citet{barras-thesis},
there was the requirement that fixpoint recursors can never occur as
arguments to other functions in their defining body.
%
For example, in order for $e$ to pass size-irrelevance typing, $e$
cannot contain a sub-expression of the form $(\app{M}{f})$.
%
We were able to get rid of this requirement in the strong
normalization proof of this alternative formulation of \lang.
%
In fact, the typing rules allowed for size-irrelevance typing can be
expanded to include counterparts for almost all of the ``normal''
typing rules.

An alternative approach seems to be to use a model involving PERs,
where the PERs are designed to ensure size-irrelevance.
%
In any case, it seems that an inherent restriction of size-irrelevance
is one may not have a recursive function $F$ with behaviours such as
$\app{F}{n} \approx \Nat^\upsilon \to ...n\text{ times}... \to
\Nat^\upsilon$ or even $\app{F}{n} \approx \Nat^\upsilon$ where
$\upsilon$ is the size variable bound by $F$.
%
\citet{cic-hat-minus} has a similar restriction present in
\CIChatminus, and this restriction matches the intuition of
size-irrelevance.
%
If $\app{F}{n} \approx \Nat^\upsilon$ then the value of $F$ on an
input $n$ depends on the size $\upsilon$, which precisely the
behaviour size-irrelevance aims to forbid.
%
On the other hand, $\app{F}{n} \approx \Nat^\infty \to
...n\text{ times}...\to\Nat^\infty$ does adhere to size-irrelevance.
\fi

\subsubsection{Computation of the Infinite Size}

An additional challenge in constructing the set-theoretic model is the
justification of $\mu$-reduction,
further complicated by the ordinal interpretation of the infinite size
$\infty$.
Consider for instance again the fixpoint
$e = \fixE{\upsilon}{f}{\Nat^\upsilon \rightarrow \Nat^\upsilon}{e'}{\infty}$
now applied to $\Zero$.
Then $\app{e}{\Zero}$ $\mu$-reduces as follows:
$$\app{\fixE{\upsilon}{f}{\Nat^\upsilon \rightarrow \Nat^\upsilon}{e'}{\infty}}{\Zero}
\rhd_\mu
\app{\subst{\subst{e'}{\upsilon}{\infty}}{f}{e}}{\Zero}$$
Let $\pi$ and $\rho$ be size and term variable valuations,
define $\psi_\alpha$ as above, and recall that if $\alpha \geq \omega$,
then $\psi_\alpha = \psi_\omega$.
Suppose then that we have an ordinal $\kappa \geq \omega$ such that we have
$\psi_{\kappa+1} = \psi_\kappa = \psi_\omega = \Val(e)_\rho^\pi$.
To justify $\mu$-reduction, we need to show the following holds:
$$\Val(\app{e}{\Zero})_\rho^\pi = \Val(\app{\subst{\subst{e'}{\upsilon}{\infty}}{f}{e}}{\Zero})_\rho^\pi$$
Let $\mathcal{O} = \Val(\Zero)_\rho^\pi$.
On the left-hand side, we have
\begin{align*}
  \Val(\app{e}{\Zero})_\rho^\pi &= \Val(e)_\rho^\pi ~ \mathcal{O} \\
  &= \psi_{\kappa}(\mathcal{O}) \\
  &= \psi_{\kappa+1}(\mathcal{O}) &\text{since $\kappa \geq \omega$} \\
  &= \phi_\kappa(\psi_\kappa)(\mathcal{O}) &\text{expanding $\psi_{\kappa+1}$} \\
  &= \Val(e')_{\subst{\rho}{f}{\psi_\kappa}}^{\subst{\pi}{\upsilon}{\kappa}} ~ \mathcal{O} &\text{by definition} \\
\end{align*}
Meanwhile, on the right-hand side,
\begin{align*}
  \Val(\app{\subst{\subst{e'}{\upsilon}{\infty}}{f}{e}}{\Zero})_\rho^\pi
  &= \Val(\subst{\subst{e'}{\upsilon}{\infty}}{f}{e})_\rho^\pi ~ \mathcal{O} \\
  &= \Val(\subst{e'}{\upsilon}{\infty})_{\subst{\rho}{f}{\psi_\kappa}}^\pi ~ \mathcal{O} &\text{by substitutivity}
\end{align*}

Then all we need to show is that
$\Val(e')_{\subst{\rho}{f}{\psi_\kappa}}^{\subst{\pi}{\upsilon}{\kappa}}
= \Val(\subst{e'}{\upsilon}{\infty})_{\subst{\rho}{f}{\psi_\kappa}}^\pi$,
moving the substitution by $\infty$ into the valuation as $\kappa$.
More generally, for any term $e$ along with valuations $\pi$, $\rho$,
there is some ordinal $\Infty(e; \upsilon)_\rho^\pi$ such that the following
infinite-size subsitutivity property holds:
$$\forall \kappa \geq \Infty(e; \upsilon)_\rho^\pi,
  \Val(e)_{\rho}^{\subst{\pi}{\upsilon}{\kappa}}
  = \Val(\subst{e}{\upsilon}{\infty})_{\rho}^{\pi}$$

This equality expresses the idea that $\Infty(e;\upsilon)_\rho^\pi$
closes off all inductive types annotated with $\upsilon$ in $e$, so
$\Infty(e;\upsilon)_\rho^\pi$ is the denotation of $\infty$ for $\upsilon$ in
$M$ under $\rho$ and $\pi$.
%
Intuitively, we know this ordinal $\Infty(e;\upsilon)_\rho^\pi$ exists,
because the strict positivity condition ensures that by iterating the
operator associated with an inductive type up to its closure ordinal,
we eventually reach their fixpoints.
%
Since there can only be finitely many inductive types in $e$, an
ordinal with the infinite-size substitutivity property is the
supremum of these closure ordinals.

However, the computation of $\Infty(e;\upsilon)_\rho^\pi$ is complicated by
the fact that in $e$, the size variable $\upsilon$ can be annotated to more
than one inductive type.
%
For example, in $e$, the size variable $\upsilon$ can be annotated to
both $J^\upsilon$ and $I^\upsilon$, where $I,J$ have different closure
ordinals and $I$ may even contain $J$ as a parameter.
%
And so, to conclude, we would like to remark that computing
$\Infty(e;\upsilon)_\rho^\pi$, despite seemingly obvious at first,
turned out to be much more involved than initially expected.
%
\todo: Is this conclusion fine?

%%% Local Variables:
%%% TeX-master: "../main.tex"
%%% TeX-engine: default
%%% End:
